{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMNxB3urXq6eHDHNoTBXwgS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guusbosman/ai-learning/blob/main/Nescio%20GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5H_jaW6STKH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimenting with chargpt.py on a Dutch text\n",
        "\n",
        "As learning exercise, I'm trying to run [chargpt.py](https://github.com/karpathy/minGPT/blob/master/projects/chargpt/chargpt.py) in Colab, using a Dutch language resource. The text I used are three short stories by author [Nescio](https://en.wikipedia.org/wiki/Nescio) -- which, in fact, constitute his complete works, around 200k characters.\n",
        "\n"
      ],
      "metadata": {
        "id": "iFZIX3_5SV3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/karpathy/minGPT.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO_YM5SmSqP5",
        "outputId": "027b2ec1-5215-4a09-ce71-c988b1b52694"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'minGPT'...\n",
            "remote: Enumerating objects: 489, done.\u001b[K\n",
            "remote: Total 489 (delta 0), reused 0 (delta 0), pack-reused 489\u001b[K\n",
            "Receiving objects: 100% (489/489), 1.44 MiB | 32.02 MiB/s, done.\n",
            "Resolving deltas: 100% (260/260), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above needs to be ran only once."
      ],
      "metadata": {
        "id": "_qSeKXH2Ula7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/minGPT\n",
        "!wget https://www.gutenberg.org/cache/epub/29719/pg29719.txt\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Trains a character-level language model.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "from mingpt.model import GPT\n",
        "from mingpt.trainer import Trainer\n",
        "from mingpt.utils import set_seed, setup_logging, CfgNode as CN\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "def get_config():\n",
        "\n",
        "    C = CN()\n",
        "\n",
        "    # system\n",
        "    C.system = CN()\n",
        "    C.system.seed = 3407\n",
        "    C.system.work_dir = './out/chargpt'\n",
        "\n",
        "    # data\n",
        "    C.data = CharDataset.get_default_config()\n",
        "\n",
        "    # model\n",
        "    C.model = GPT.get_default_config()\n",
        "    C.model.model_type = 'gpt-mini'\n",
        "\n",
        "    # trainer\n",
        "    C.trainer = Trainer.get_default_config()\n",
        "    C.trainer.learning_rate = 5e-4 # the model we're using is so small that we can go a bit faster\n",
        "\n",
        "    return C\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "class CharDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Emits batches of characters\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def get_default_config():\n",
        "        C = CN()\n",
        "        C.block_size = 128\n",
        "        return C\n",
        "\n",
        "    def __init__(self, config, data):\n",
        "        self.config = config\n",
        "\n",
        "        chars = sorted(list(set(data)))\n",
        "        data_size, vocab_size = len(data), len(chars)\n",
        "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
        "\n",
        "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
        "        self.vocab_size = vocab_size\n",
        "        self.data = data\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return self.vocab_size\n",
        "\n",
        "    def get_block_size(self):\n",
        "        return self.config.block_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.config.block_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # grab a chunk of (block_size + 1) characters from the data\n",
        "        chunk = self.data[idx:idx + self.config.block_size + 1]\n",
        "        # encode every character to an integer\n",
        "        dix = [self.stoi[s] for s in chunk]\n",
        "        # return as tensors\n",
        "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
        "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # get default config and overrides from the command line, if any\n",
        "    config = get_config()\n",
        "    #config.merge_from_args(sys.argv[1:])\n",
        "    print(config)\n",
        "    setup_logging(config)\n",
        "    set_seed(config.system.seed)\n",
        "\n",
        "    # construct the training dataset\n",
        "    text = open('pg29719.txt', 'r').read() # don't worry we won't run out of file handles\n",
        "    train_dataset = CharDataset(config.data, text)\n",
        "\n",
        "    # construct the model\n",
        "    config.model.vocab_size = train_dataset.get_vocab_size()\n",
        "    config.model.block_size = train_dataset.get_block_size()\n",
        "    model = GPT(config.model)\n",
        "\n",
        "    # construct the trainer object\n",
        "    trainer = Trainer(config.trainer, model, train_dataset)\n",
        "\n",
        "    # iteration callback\n",
        "    def batch_end_callback(trainer):\n",
        "\n",
        "        if trainer.iter_num % 10 == 0:\n",
        "            print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
        "\n",
        "        if trainer.iter_num % 500 == 0:\n",
        "            # evaluate both the train and test score\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                # sample from the model...\n",
        "                context = \"O God, O God!\"\n",
        "                x = torch.tensor([train_dataset.stoi[s] for s in context], dtype=torch.long)[None,...].to(trainer.device)\n",
        "                y = model.generate(x, 500, temperature=1.0, do_sample=True, top_k=10)[0]\n",
        "                completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
        "                print(completion)\n",
        "            # save the latest model\n",
        "            print(\"saving model\")\n",
        "            ckpt_path = os.path.join(config.system.work_dir, \"model.pt\")\n",
        "            torch.save(model.state_dict(), ckpt_path)\n",
        "            # revert model to training mode\n",
        "            model.train()\n",
        "\n",
        "    trainer.set_callback('on_batch_end', batch_end_callback)\n",
        "\n",
        "    # run the optimization\n",
        "    trainer.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SOw_Y1bOUohZ",
        "outputId": "a20490a8-2899-41be-c8fc-f0f84db76c43"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/minGPT\n",
            "--2023-06-13 01:45:06--  https://www.gutenberg.org/cache/epub/29719/pg29719.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 226936 (222K) [text/plain]\n",
            "Saving to: ‘pg29719.txt’\n",
            "\n",
            "pg29719.txt         100%[===================>] 221.62K   325KB/s    in 0.7s    \n",
            "\n",
            "2023-06-13 01:45:08 (325 KB/s) - ‘pg29719.txt’ saved [226936/226936]\n",
            "\n",
            "system:\n",
            "    seed: 3407\n",
            "    work_dir: ./out/chargpt\n",
            "data:\n",
            "    block_size: 128\n",
            "model:\n",
            "    model_type: gpt-mini\n",
            "    n_layer: None\n",
            "    n_head: None\n",
            "    n_embd: None\n",
            "    vocab_size: None\n",
            "    block_size: None\n",
            "    embd_pdrop: 0.1\n",
            "    resid_pdrop: 0.1\n",
            "    attn_pdrop: 0.1\n",
            "trainer:\n",
            "    device: auto\n",
            "    num_workers: 4\n",
            "    max_iters: None\n",
            "    batch_size: 64\n",
            "    learning_rate: 0.0005\n",
            "    betas: (0.9, 0.95)\n",
            "    weight_decay: 0.1\n",
            "    grad_norm_clip: 1.0\n",
            "\n",
            "data has 222444 characters, 99 unique.\n",
            "number of parameters: 2.71M\n",
            "running on device cuda\n",
            "iter_dt 0.00ms; iter 0: train loss 4.63225\n",
            "O God, O God!eun nOO nnp  nepurK eued d$ptOd nK nt  a a K t$utnKtaen Kate  dt nd t,pten  ap ean d, tpen pnr d K  e  eaKt   nnndddette autaKpaateeu a KpK Kae e h$aKpa ha  K tnO  a n hatptn aae de antaKpnpptpeKdeddnt  npoaupta tp   ean hK t p Kao Kt ht p   pndn tep nernn auKdtd hnO n   ept nK  o K eKn n Kapttu ndpt do ate tddon er n KtdnO ed$ ha nudK dtKadddaadtdeaadp p  nK$pdteeta t out p tn en nOneKtKanuh an opon Kanee pe dp e  d epaKteaKKra aadp n o  Kedae  eaoata e  taeat n hpeuedpK p dn haa en eKedn auu K\n",
            "saving model\n",
            "iter_dt 28.33ms; iter 10: train loss 3.10838\n",
            "iter_dt 27.92ms; iter 20: train loss 2.72306\n",
            "iter_dt 28.20ms; iter 30: train loss 2.66118\n",
            "iter_dt 28.60ms; iter 40: train loss 2.53505\n",
            "iter_dt 28.28ms; iter 50: train loss 2.54404\n",
            "iter_dt 28.88ms; iter 60: train loss 2.47433\n",
            "iter_dt 28.95ms; iter 70: train loss 2.48152\n",
            "iter_dt 27.81ms; iter 80: train loss 2.44625\n",
            "iter_dt 27.80ms; iter 90: train loss 2.43719\n",
            "iter_dt 27.57ms; iter 100: train loss 2.42785\n",
            "iter_dt 27.65ms; iter 110: train loss 2.45535\n",
            "iter_dt 27.57ms; iter 120: train loss 2.40751\n",
            "iter_dt 27.13ms; iter 130: train loss 2.36558\n",
            "iter_dt 27.36ms; iter 140: train loss 2.39055\n",
            "iter_dt 27.32ms; iter 150: train loss 2.37471\n",
            "iter_dt 27.24ms; iter 160: train loss 2.35537\n",
            "iter_dt 27.39ms; iter 170: train loss 2.40141\n",
            "iter_dt 27.18ms; iter 180: train loss 2.31499\n",
            "iter_dt 27.28ms; iter 190: train loss 2.35324\n",
            "iter_dt 27.27ms; iter 200: train loss 2.40223\n",
            "iter_dt 27.21ms; iter 210: train loss 2.28445\n",
            "iter_dt 27.87ms; iter 220: train loss 2.32813\n",
            "iter_dt 28.51ms; iter 230: train loss 2.32347\n",
            "iter_dt 30.78ms; iter 240: train loss 2.35827\n",
            "iter_dt 28.13ms; iter 250: train loss 2.29365\n",
            "iter_dt 27.54ms; iter 260: train loss 2.27909\n",
            "iter_dt 27.17ms; iter 270: train loss 2.26054\n",
            "iter_dt 27.71ms; iter 280: train loss 2.24642\n",
            "iter_dt 27.11ms; iter 290: train loss 2.26107\n",
            "iter_dt 27.53ms; iter 300: train loss 2.25349\n",
            "iter_dt 27.38ms; iter 310: train loss 2.22211\n",
            "iter_dt 27.33ms; iter 320: train loss 2.20925\n",
            "iter_dt 27.21ms; iter 330: train loss 2.23247\n",
            "iter_dt 29.61ms; iter 340: train loss 2.14979\n",
            "iter_dt 29.22ms; iter 350: train loss 2.14210\n",
            "iter_dt 29.64ms; iter 360: train loss 2.13816\n",
            "iter_dt 30.38ms; iter 370: train loss 2.14563\n",
            "iter_dt 29.62ms; iter 380: train loss 2.09705\n",
            "iter_dt 29.17ms; iter 390: train loss 2.09835\n",
            "iter_dt 31.15ms; iter 400: train loss 2.08176\n",
            "iter_dt 29.29ms; iter 410: train loss 2.07054\n",
            "iter_dt 27.27ms; iter 420: train loss 2.04253\n",
            "iter_dt 27.65ms; iter 430: train loss 1.99160\n",
            "iter_dt 27.60ms; iter 440: train loss 2.07460\n",
            "iter_dt 27.52ms; iter 450: train loss 1.97921\n",
            "iter_dt 27.41ms; iter 460: train loss 1.98999\n",
            "iter_dt 28.40ms; iter 470: train loss 1.97967\n",
            "iter_dt 29.77ms; iter 480: train loss 1.95117\n",
            "iter_dt 29.64ms; iter 490: train loss 1.96669\n",
            "iter_dt 28.48ms; iter 500: train loss 1.98030\n",
            "O God, O God! I, dat de burs een\n",
            "heef op dat zei, haar mals dacht de zei vrijn en eeschaan. Wiltij haar zoef\n",
            "ik op er haarmet van en om de stotjes de waaren in voereed, ik\n",
            "kaneek z'n had over van wilderde doof toed doe hoeden?\" Is in daar\n",
            "wond een gaamen zest zou zoo van voeren, de del den van\n",
            "al hij me heeme vand van gon draat op z'n voedene verkorgerd diet\n",
            "koes opte hemt ond zoo ik geschadens wam op het zageend veellen dondje de eer de\n",
            "dat naar de verral de van geschiller wijd en een datst een een\n",
            "gendas a\n",
            "saving model\n",
            "iter_dt 27.31ms; iter 510: train loss 1.91274\n",
            "iter_dt 27.32ms; iter 520: train loss 1.92398\n",
            "iter_dt 27.53ms; iter 530: train loss 1.93335\n",
            "iter_dt 29.25ms; iter 540: train loss 1.92042\n",
            "iter_dt 27.50ms; iter 550: train loss 1.90935\n",
            "iter_dt 29.39ms; iter 560: train loss 1.83962\n",
            "iter_dt 27.48ms; iter 570: train loss 1.88747\n",
            "iter_dt 28.27ms; iter 580: train loss 1.89222\n",
            "iter_dt 28.62ms; iter 590: train loss 1.85514\n",
            "iter_dt 27.27ms; iter 600: train loss 1.88683\n",
            "iter_dt 27.49ms; iter 610: train loss 1.82363\n",
            "iter_dt 27.93ms; iter 620: train loss 1.87394\n",
            "iter_dt 27.16ms; iter 630: train loss 1.79935\n",
            "iter_dt 27.12ms; iter 640: train loss 1.79464\n",
            "iter_dt 27.37ms; iter 650: train loss 1.84379\n",
            "iter_dt 27.46ms; iter 660: train loss 1.79235\n",
            "iter_dt 27.20ms; iter 670: train loss 1.79526\n",
            "iter_dt 27.42ms; iter 680: train loss 1.79086\n",
            "iter_dt 27.39ms; iter 690: train loss 1.73794\n",
            "iter_dt 27.26ms; iter 700: train loss 1.80090\n",
            "iter_dt 27.10ms; iter 710: train loss 1.72466\n",
            "iter_dt 27.11ms; iter 720: train loss 1.79939\n",
            "iter_dt 27.21ms; iter 730: train loss 1.74153\n",
            "iter_dt 28.01ms; iter 740: train loss 1.75280\n",
            "iter_dt 27.78ms; iter 750: train loss 1.73867\n",
            "iter_dt 27.50ms; iter 760: train loss 1.72363\n",
            "iter_dt 27.24ms; iter 770: train loss 1.73703\n",
            "iter_dt 27.80ms; iter 780: train loss 1.73173\n",
            "iter_dt 27.35ms; iter 790: train loss 1.71794\n",
            "iter_dt 27.84ms; iter 800: train loss 1.71050\n",
            "iter_dt 27.57ms; iter 810: train loss 1.69270\n",
            "iter_dt 27.36ms; iter 820: train loss 1.69788\n",
            "iter_dt 27.45ms; iter 830: train loss 1.70379\n",
            "iter_dt 27.93ms; iter 840: train loss 1.68722\n",
            "iter_dt 27.35ms; iter 850: train loss 1.70701\n",
            "iter_dt 27.27ms; iter 860: train loss 1.64678\n",
            "iter_dt 27.47ms; iter 870: train loss 1.65481\n",
            "iter_dt 27.21ms; iter 880: train loss 1.66070\n",
            "iter_dt 27.31ms; iter 890: train loss 1.65748\n",
            "iter_dt 27.34ms; iter 900: train loss 1.66642\n",
            "iter_dt 27.19ms; iter 910: train loss 1.61396\n",
            "iter_dt 27.64ms; iter 920: train loss 1.61401\n",
            "iter_dt 27.28ms; iter 930: train loss 1.61673\n",
            "iter_dt 27.25ms; iter 940: train loss 1.63271\n",
            "iter_dt 28.97ms; iter 950: train loss 1.64442\n",
            "iter_dt 27.47ms; iter 960: train loss 1.63047\n",
            "iter_dt 27.29ms; iter 970: train loss 1.61917\n",
            "iter_dt 27.39ms; iter 980: train loss 1.60332\n",
            "iter_dt 27.45ms; iter 990: train loss 1.60269\n",
            "iter_dt 27.79ms; iter 1000: train loss 1.54447\n",
            "O God, O God! Is biesteren er zelfde hand\n",
            "en geven wit zoo gehand. En wat zei ik zijn op nog meer, nieuw, dat wit was vuor. Hij\n",
            "waren dat niks was maal, als nooiil met ze zoulven.\n",
            "\n",
            "Maar dan dan tonden heelemalen, toent naar beziefdig heuis, over\n",
            "dat den schragen. Dora i weg een meer neem. Een zei i een kleet blauwsten\n",
            "was moest en knapplook best verschij, dan zooals wees in 't benait zinnen. Er wan\n",
            "met wweet op deek van de leven en klampte over was gedrhouden, ondergal\n",
            "weer en gelende sische en hoe of meer d\n",
            "saving model\n",
            "iter_dt 27.62ms; iter 1010: train loss 1.54943\n",
            "iter_dt 28.13ms; iter 1020: train loss 1.59187\n",
            "iter_dt 27.74ms; iter 1030: train loss 1.57413\n",
            "iter_dt 28.34ms; iter 1040: train loss 1.58665\n",
            "iter_dt 27.90ms; iter 1050: train loss 1.55425\n",
            "iter_dt 28.02ms; iter 1060: train loss 1.55557\n",
            "iter_dt 28.27ms; iter 1070: train loss 1.57834\n",
            "iter_dt 28.11ms; iter 1080: train loss 1.52057\n",
            "iter_dt 27.31ms; iter 1090: train loss 1.52242\n",
            "iter_dt 27.74ms; iter 1100: train loss 1.55911\n",
            "iter_dt 27.43ms; iter 1110: train loss 1.59114\n",
            "iter_dt 27.54ms; iter 1120: train loss 1.62290\n",
            "iter_dt 27.95ms; iter 1130: train loss 1.48448\n",
            "iter_dt 27.39ms; iter 1140: train loss 1.53636\n",
            "iter_dt 27.25ms; iter 1150: train loss 1.54776\n",
            "iter_dt 27.72ms; iter 1160: train loss 1.49961\n",
            "iter_dt 27.83ms; iter 1170: train loss 1.46642\n",
            "iter_dt 27.38ms; iter 1180: train loss 1.49217\n",
            "iter_dt 27.31ms; iter 1190: train loss 1.50639\n",
            "iter_dt 27.72ms; iter 1200: train loss 1.51812\n",
            "iter_dt 27.43ms; iter 1210: train loss 1.48609\n",
            "iter_dt 27.34ms; iter 1220: train loss 1.46002\n",
            "iter_dt 27.41ms; iter 1230: train loss 1.46503\n",
            "iter_dt 27.21ms; iter 1240: train loss 1.42454\n",
            "iter_dt 27.39ms; iter 1250: train loss 1.51693\n",
            "iter_dt 30.03ms; iter 1260: train loss 1.48618\n",
            "iter_dt 27.49ms; iter 1270: train loss 1.44648\n",
            "iter_dt 27.64ms; iter 1280: train loss 1.43372\n",
            "iter_dt 27.41ms; iter 1290: train loss 1.47824\n",
            "iter_dt 27.28ms; iter 1300: train loss 1.45924\n",
            "iter_dt 27.61ms; iter 1310: train loss 1.44372\n",
            "iter_dt 27.21ms; iter 1320: train loss 1.45846\n",
            "iter_dt 27.33ms; iter 1330: train loss 1.40429\n",
            "iter_dt 27.38ms; iter 1340: train loss 1.43821\n",
            "iter_dt 27.36ms; iter 1350: train loss 1.43478\n",
            "iter_dt 27.04ms; iter 1360: train loss 1.45718\n",
            "iter_dt 27.20ms; iter 1370: train loss 1.38290\n",
            "iter_dt 27.08ms; iter 1380: train loss 1.41170\n",
            "iter_dt 27.02ms; iter 1390: train loss 1.41077\n",
            "iter_dt 27.39ms; iter 1400: train loss 1.38084\n",
            "iter_dt 27.32ms; iter 1410: train loss 1.44161\n",
            "iter_dt 27.24ms; iter 1420: train loss 1.42465\n",
            "iter_dt 27.48ms; iter 1430: train loss 1.40782\n",
            "iter_dt 27.23ms; iter 1440: train loss 1.41677\n",
            "iter_dt 27.22ms; iter 1450: train loss 1.34472\n",
            "iter_dt 27.18ms; iter 1460: train loss 1.36534\n",
            "iter_dt 27.11ms; iter 1470: train loss 1.39222\n",
            "iter_dt 27.08ms; iter 1480: train loss 1.34473\n",
            "iter_dt 27.19ms; iter 1490: train loss 1.37248\n",
            "iter_dt 27.08ms; iter 1500: train loss 1.34416\n",
            "O God, O God! No. En toe kan- hij\n",
            "dan dat zoo ook, dat ze 't, avonds herd over hem op hun trap\n",
            "heugen, aan de wijlen of te zeggen. En op haar enoedig, vertielde zag z'n verschicht,\n",
            "maar eenige schider tot zelf nog en dat heel greest om. En de boogen wat\n",
            "niks meer zag hij met den handel nog waar boven.\n",
            "\n",
            "En zei Bavink, wat ze zit wij van z'n beetjes heer met\n",
            "een pijs af, die zien? En wier zag je heer aan weer anders en dat ze\n",
            "oude hem. Het wezelfsleven viel was zoo veel gaan, dat i nog haar schoof ofdat,\n",
            "ze wo\n",
            "saving model\n",
            "iter_dt 27.72ms; iter 1510: train loss 1.36501\n",
            "iter_dt 27.78ms; iter 1520: train loss 1.34885\n",
            "iter_dt 27.57ms; iter 1530: train loss 1.37313\n",
            "iter_dt 27.39ms; iter 1540: train loss 1.32804\n",
            "iter_dt 27.61ms; iter 1550: train loss 1.34324\n",
            "iter_dt 27.56ms; iter 1560: train loss 1.33586\n",
            "iter_dt 28.42ms; iter 1570: train loss 1.33329\n",
            "iter_dt 27.60ms; iter 1580: train loss 1.34919\n",
            "iter_dt 28.39ms; iter 1590: train loss 1.33300\n",
            "iter_dt 27.83ms; iter 1600: train loss 1.38159\n",
            "iter_dt 27.57ms; iter 1610: train loss 1.33084\n",
            "iter_dt 27.55ms; iter 1620: train loss 1.31721\n",
            "iter_dt 27.78ms; iter 1630: train loss 1.36294\n",
            "iter_dt 27.86ms; iter 1640: train loss 1.31674\n",
            "iter_dt 27.93ms; iter 1650: train loss 1.33876\n",
            "iter_dt 28.37ms; iter 1660: train loss 1.34195\n",
            "iter_dt 28.18ms; iter 1670: train loss 1.32813\n",
            "iter_dt 28.41ms; iter 1680: train loss 1.29858\n",
            "iter_dt 28.50ms; iter 1690: train loss 1.31086\n",
            "iter_dt 27.81ms; iter 1700: train loss 1.27003\n",
            "iter_dt 28.21ms; iter 1710: train loss 1.28943\n",
            "iter_dt 28.12ms; iter 1720: train loss 1.27461\n",
            "iter_dt 28.15ms; iter 1730: train loss 1.28188\n",
            "iter_dt 28.03ms; iter 1740: train loss 1.29108\n",
            "iter_dt 27.56ms; iter 1750: train loss 1.27779\n",
            "iter_dt 27.51ms; iter 1760: train loss 1.25347\n",
            "iter_dt 27.55ms; iter 1770: train loss 1.28132\n",
            "iter_dt 27.36ms; iter 1780: train loss 1.23809\n",
            "iter_dt 28.14ms; iter 1790: train loss 1.30055\n",
            "iter_dt 27.33ms; iter 1800: train loss 1.25036\n",
            "iter_dt 27.76ms; iter 1810: train loss 1.26870\n",
            "iter_dt 27.51ms; iter 1820: train loss 1.23413\n",
            "iter_dt 27.74ms; iter 1830: train loss 1.26173\n",
            "iter_dt 27.23ms; iter 1840: train loss 1.26983\n",
            "iter_dt 27.31ms; iter 1850: train loss 1.23582\n",
            "iter_dt 27.35ms; iter 1860: train loss 1.28581\n",
            "iter_dt 27.87ms; iter 1870: train loss 1.22822\n",
            "iter_dt 27.38ms; iter 1880: train loss 1.22675\n",
            "iter_dt 28.16ms; iter 1890: train loss 1.24994\n",
            "iter_dt 27.92ms; iter 1900: train loss 1.22294\n",
            "iter_dt 27.31ms; iter 1910: train loss 1.27593\n",
            "iter_dt 27.30ms; iter 1920: train loss 1.22296\n",
            "iter_dt 27.69ms; iter 1930: train loss 1.21317\n",
            "iter_dt 27.17ms; iter 1940: train loss 1.20632\n",
            "iter_dt 27.39ms; iter 1950: train loss 1.17120\n",
            "iter_dt 27.59ms; iter 1960: train loss 1.18153\n",
            "iter_dt 27.14ms; iter 1970: train loss 1.21291\n",
            "iter_dt 27.49ms; iter 1980: train loss 1.21599\n",
            "iter_dt 27.08ms; iter 1990: train loss 1.23119\n",
            "iter_dt 27.36ms; iter 2000: train loss 1.20576\n",
            "O God, O God! Oop en altijd had het pas een\n",
            "maar dure stoeltje, een het wat rooken van en sloeg. Ze van aux compeende\n",
            "worst en op haar stand en hem het handen te vijftien. 's avonds\n",
            "lieve had een half meizier, hardop in 't zoete i dat een geschuit zoend. \"Moet\n",
            "Je kruin je beter vroeger die wachten dan zou ik vaderen. Je\n",
            "was noemde ze weer toen niet te zoen. En als ze begreep een het poot voor. De\n",
            "coorweg, dat ik een groote, dan zou zien dat ik er ook waren geen aan t'n\n",
            "schoren bulletje, de hooge zon\n",
            "hebben, \n",
            "saving model\n",
            "iter_dt 27.55ms; iter 2010: train loss 1.20116\n",
            "iter_dt 27.34ms; iter 2020: train loss 1.17439\n",
            "iter_dt 27.13ms; iter 2030: train loss 1.19165\n",
            "iter_dt 27.15ms; iter 2040: train loss 1.16620\n",
            "iter_dt 27.35ms; iter 2050: train loss 1.17750\n",
            "iter_dt 27.21ms; iter 2060: train loss 1.16682\n",
            "iter_dt 27.41ms; iter 2070: train loss 1.18609\n",
            "iter_dt 27.26ms; iter 2080: train loss 1.17827\n",
            "iter_dt 27.36ms; iter 2090: train loss 1.16980\n",
            "iter_dt 27.33ms; iter 2100: train loss 1.16368\n",
            "iter_dt 27.42ms; iter 2110: train loss 1.13455\n",
            "iter_dt 27.41ms; iter 2120: train loss 1.18103\n",
            "iter_dt 27.23ms; iter 2130: train loss 1.14888\n",
            "iter_dt 27.23ms; iter 2140: train loss 1.17906\n",
            "iter_dt 28.10ms; iter 2150: train loss 1.13710\n",
            "iter_dt 27.72ms; iter 2160: train loss 1.11427\n",
            "iter_dt 27.40ms; iter 2170: train loss 1.13091\n",
            "iter_dt 27.36ms; iter 2180: train loss 1.14676\n",
            "iter_dt 27.29ms; iter 2190: train loss 1.11567\n",
            "iter_dt 27.19ms; iter 2200: train loss 1.13482\n",
            "iter_dt 27.28ms; iter 2210: train loss 1.12153\n",
            "iter_dt 27.23ms; iter 2220: train loss 1.13265\n",
            "iter_dt 27.54ms; iter 2230: train loss 1.09135\n",
            "iter_dt 27.27ms; iter 2240: train loss 1.11385\n",
            "iter_dt 28.14ms; iter 2250: train loss 1.14243\n",
            "iter_dt 27.28ms; iter 2260: train loss 1.10355\n",
            "iter_dt 27.44ms; iter 2270: train loss 1.10283\n",
            "iter_dt 27.23ms; iter 2280: train loss 1.09142\n",
            "iter_dt 27.67ms; iter 2290: train loss 1.08419\n",
            "iter_dt 27.55ms; iter 2300: train loss 1.11984\n",
            "iter_dt 27.31ms; iter 2310: train loss 1.11710\n",
            "iter_dt 27.17ms; iter 2320: train loss 1.10425\n",
            "iter_dt 27.25ms; iter 2330: train loss 1.11007\n",
            "iter_dt 27.19ms; iter 2340: train loss 1.09351\n",
            "iter_dt 27.34ms; iter 2350: train loss 1.09969\n",
            "iter_dt 27.68ms; iter 2360: train loss 1.05994\n",
            "iter_dt 27.13ms; iter 2370: train loss 1.07170\n",
            "iter_dt 27.36ms; iter 2380: train loss 1.09636\n",
            "iter_dt 27.38ms; iter 2390: train loss 1.03364\n",
            "iter_dt 27.44ms; iter 2400: train loss 1.09227\n",
            "iter_dt 27.64ms; iter 2410: train loss 1.08491\n",
            "iter_dt 27.48ms; iter 2420: train loss 1.04283\n",
            "iter_dt 27.20ms; iter 2430: train loss 1.05984\n",
            "iter_dt 27.46ms; iter 2440: train loss 1.07137\n",
            "iter_dt 27.10ms; iter 2450: train loss 1.03745\n",
            "iter_dt 27.54ms; iter 2460: train loss 1.07213\n",
            "iter_dt 27.07ms; iter 2470: train loss 1.07356\n",
            "iter_dt 27.21ms; iter 2480: train loss 1.07300\n",
            "iter_dt 27.11ms; iter 2490: train loss 1.03517\n",
            "iter_dt 27.68ms; iter 2500: train loss 1.03299\n",
            "O God, O God!\" Een groene brank en smalleerbij\n",
            "dat was ze niet aangenieten.\n",
            "\n",
            "En 't Artikeltje was er van een karaar blauwe aan en een kiel en van leste\n",
            "draaien haar sneeuwbannen.\n",
            "\n",
            "Een blauwige juffranje in mijn einzielboog van zak en ook een neer\n",
            "oogenblik.\"\n",
            "\n",
            "Ik ging uit de gorde natte kast waarom. Japi staat voor elkaar op 's\n",
            "baas en verdriet in er niets van. Haar linkers van te plazen,\n",
            "de diuite om haar manten, en te lag 't niet op eens in z'n vieren stoel\n",
            "weg.\n",
            "\n",
            "\"Daarom laat lolligleid van 't water zit.\" E\n",
            "saving model\n",
            "iter_dt 27.66ms; iter 2510: train loss 1.04608\n",
            "iter_dt 27.70ms; iter 2520: train loss 1.04149\n",
            "iter_dt 27.45ms; iter 2530: train loss 1.03315\n",
            "iter_dt 27.64ms; iter 2540: train loss 1.03901\n",
            "iter_dt 28.69ms; iter 2550: train loss 1.00609\n",
            "iter_dt 27.38ms; iter 2560: train loss 0.99925\n",
            "iter_dt 27.49ms; iter 2570: train loss 0.98532\n",
            "iter_dt 27.38ms; iter 2580: train loss 0.98456\n",
            "iter_dt 27.80ms; iter 2590: train loss 1.02796\n",
            "iter_dt 27.46ms; iter 2600: train loss 0.99351\n",
            "iter_dt 27.34ms; iter 2610: train loss 0.98536\n",
            "iter_dt 27.75ms; iter 2620: train loss 1.01755\n",
            "iter_dt 27.26ms; iter 2630: train loss 1.01557\n",
            "iter_dt 27.50ms; iter 2640: train loss 1.00251\n",
            "iter_dt 29.26ms; iter 2650: train loss 0.98613\n",
            "iter_dt 27.62ms; iter 2660: train loss 0.97100\n",
            "iter_dt 27.42ms; iter 2670: train loss 1.00286\n",
            "iter_dt 27.35ms; iter 2680: train loss 0.95928\n",
            "iter_dt 27.49ms; iter 2690: train loss 0.98551\n",
            "iter_dt 28.14ms; iter 2700: train loss 0.97611\n",
            "iter_dt 27.85ms; iter 2710: train loss 0.93760\n",
            "iter_dt 27.71ms; iter 2720: train loss 0.96642\n",
            "iter_dt 28.33ms; iter 2730: train loss 0.97954\n",
            "iter_dt 27.72ms; iter 2740: train loss 0.94884\n",
            "iter_dt 27.74ms; iter 2750: train loss 0.93029\n",
            "iter_dt 27.66ms; iter 2760: train loss 0.96069\n",
            "iter_dt 27.82ms; iter 2770: train loss 0.97026\n",
            "iter_dt 28.47ms; iter 2780: train loss 0.98387\n",
            "iter_dt 27.65ms; iter 2790: train loss 0.91573\n",
            "iter_dt 27.56ms; iter 2800: train loss 0.94661\n",
            "iter_dt 27.01ms; iter 2810: train loss 0.95126\n",
            "iter_dt 27.26ms; iter 2820: train loss 0.97199\n",
            "iter_dt 27.03ms; iter 2830: train loss 0.94606\n",
            "iter_dt 27.44ms; iter 2840: train loss 0.95619\n",
            "iter_dt 27.07ms; iter 2850: train loss 0.88313\n",
            "iter_dt 27.22ms; iter 2860: train loss 0.94217\n",
            "iter_dt 27.52ms; iter 2870: train loss 0.94202\n",
            "iter_dt 27.00ms; iter 2880: train loss 0.93628\n",
            "iter_dt 27.12ms; iter 2890: train loss 0.92728\n",
            "iter_dt 27.01ms; iter 2900: train loss 0.91943\n",
            "iter_dt 27.02ms; iter 2910: train loss 0.92758\n",
            "iter_dt 27.67ms; iter 2920: train loss 0.89983\n",
            "iter_dt 27.62ms; iter 2930: train loss 0.91714\n",
            "iter_dt 27.54ms; iter 2940: train loss 0.90132\n",
            "iter_dt 27.65ms; iter 2950: train loss 0.88526\n",
            "iter_dt 27.90ms; iter 2960: train loss 0.87819\n",
            "iter_dt 27.54ms; iter 2970: train loss 0.91516\n",
            "iter_dt 27.66ms; iter 2980: train loss 0.94318\n",
            "iter_dt 28.71ms; iter 2990: train loss 0.87084\n",
            "iter_dt 27.88ms; iter 3000: train loss 0.89607\n",
            "O God, O God! Als-i in de steven lager daar gelezen,\n",
            "met verlangd jaar er boven. Dan was ik er nergens in. Het was een\n",
            "raam van hoog.\n",
            "\n",
            "Op een ander hoofd stond er geweest. En toen ik daar goed was een tijd naar\n",
            "uit een beetje stroomen en de somberhooge schitterenden van een\n",
            "dichtertje en niet meer op. De overzij had ik gehad overalen,\n",
            "dan moet Bavink op een meid voor de lantaarn geluiden, zag ze weer\n",
            "een duidelijk leven zich neem.\n",
            "\n",
            "Maar met de zaken heel en das 'm niet een dertje heelemaal in een den hand\n",
            "va\n",
            "saving model\n",
            "iter_dt 27.80ms; iter 3010: train loss 0.90073\n",
            "iter_dt 28.22ms; iter 3020: train loss 0.86664\n",
            "iter_dt 27.60ms; iter 3030: train loss 0.89981\n",
            "iter_dt 27.90ms; iter 3040: train loss 0.88943\n",
            "iter_dt 27.49ms; iter 3050: train loss 0.87383\n",
            "iter_dt 27.78ms; iter 3060: train loss 0.88458\n",
            "iter_dt 27.87ms; iter 3070: train loss 0.89275\n",
            "iter_dt 27.85ms; iter 3080: train loss 0.87631\n",
            "iter_dt 27.18ms; iter 3090: train loss 0.85144\n",
            "iter_dt 27.68ms; iter 3100: train loss 0.85162\n",
            "iter_dt 27.12ms; iter 3110: train loss 0.86028\n",
            "iter_dt 28.81ms; iter 3120: train loss 0.85510\n",
            "iter_dt 27.43ms; iter 3130: train loss 0.87196\n",
            "iter_dt 27.73ms; iter 3140: train loss 0.85247\n",
            "iter_dt 27.39ms; iter 3150: train loss 0.84935\n",
            "iter_dt 27.72ms; iter 3160: train loss 0.85921\n",
            "iter_dt 27.72ms; iter 3170: train loss 0.83098\n",
            "iter_dt 27.79ms; iter 3180: train loss 0.87195\n",
            "iter_dt 27.73ms; iter 3190: train loss 0.84671\n",
            "iter_dt 27.14ms; iter 3200: train loss 0.86069\n",
            "iter_dt 27.26ms; iter 3210: train loss 0.82929\n",
            "iter_dt 27.24ms; iter 3220: train loss 0.85415\n",
            "iter_dt 27.76ms; iter 3230: train loss 0.81221\n",
            "iter_dt 27.16ms; iter 3240: train loss 0.84269\n",
            "iter_dt 27.05ms; iter 3250: train loss 0.83510\n",
            "iter_dt 27.10ms; iter 3260: train loss 0.80679\n",
            "iter_dt 27.33ms; iter 3270: train loss 0.79813\n",
            "iter_dt 27.13ms; iter 3280: train loss 0.79442\n",
            "iter_dt 27.33ms; iter 3290: train loss 0.81015\n",
            "iter_dt 27.01ms; iter 3300: train loss 0.83429\n",
            "iter_dt 27.63ms; iter 3310: train loss 0.78423\n",
            "iter_dt 27.19ms; iter 3320: train loss 0.81759\n",
            "iter_dt 27.27ms; iter 3330: train loss 0.78139\n",
            "iter_dt 27.40ms; iter 3340: train loss 0.80149\n",
            "iter_dt 27.14ms; iter 3350: train loss 0.82291\n",
            "iter_dt 28.49ms; iter 3360: train loss 0.81045\n",
            "iter_dt 27.54ms; iter 3370: train loss 0.81488\n",
            "iter_dt 28.45ms; iter 3380: train loss 0.77272\n",
            "iter_dt 30.29ms; iter 3390: train loss 0.78984\n",
            "iter_dt 29.93ms; iter 3400: train loss 0.79803\n",
            "iter_dt 27.82ms; iter 3410: train loss 0.78057\n",
            "iter_dt 29.10ms; iter 3420: train loss 0.77674\n",
            "iter_dt 27.61ms; iter 3430: train loss 0.78218\n",
            "iter_dt 29.17ms; iter 3440: train loss 0.75450\n",
            "iter_dt 27.30ms; iter 3450: train loss 0.81153\n",
            "iter_dt 29.25ms; iter 3460: train loss 0.75254\n",
            "iter_dt 27.19ms; iter 3470: train loss 0.76673\n",
            "iter_dt 29.18ms; iter 3480: train loss 0.78316\n",
            "iter_dt 29.81ms; iter 3490: train loss 0.75469\n",
            "iter_dt 29.66ms; iter 3500: train loss 0.76047\n",
            "O God, O God!\" En\n",
            "niks ten dan steil gemaakt. Bekker had al een tijd geschreven op Rhenen,\n",
            "die de bloemen mochten kende mee, die 'm be stonden die met waar hebben\n",
            "geworden. Hij werkte zich af verder domde de deur over de wereld. En dan\n",
            "zei Bekker er niets meer toen dan een dichteresje mensch en heel in\n",
            "'t midden een zonnete bewegende moest een klein, die geel van de deur den kanten\n",
            "bij het tusschen de huizen in de machenten en de hoogte met de gesloten\n",
            "van haar bloemen, die haar ons vast eieren half. Maar to\n",
            "saving model\n",
            "iter_dt 27.47ms; iter 3510: train loss 0.77084\n",
            "iter_dt 30.01ms; iter 3520: train loss 0.73839\n",
            "iter_dt 29.92ms; iter 3530: train loss 0.75770\n",
            "iter_dt 29.99ms; iter 3540: train loss 0.76508\n",
            "iter_dt 30.41ms; iter 3550: train loss 0.74392\n",
            "iter_dt 27.35ms; iter 3560: train loss 0.73473\n",
            "iter_dt 27.19ms; iter 3570: train loss 0.73766\n",
            "iter_dt 27.40ms; iter 3580: train loss 0.73319\n",
            "iter_dt 27.53ms; iter 3590: train loss 0.73486\n",
            "iter_dt 27.52ms; iter 3600: train loss 0.74707\n",
            "iter_dt 27.53ms; iter 3610: train loss 0.72570\n",
            "iter_dt 28.52ms; iter 3620: train loss 0.74564\n",
            "iter_dt 27.23ms; iter 3630: train loss 0.72835\n",
            "iter_dt 27.26ms; iter 3640: train loss 0.72122\n",
            "iter_dt 27.22ms; iter 3650: train loss 0.71994\n",
            "iter_dt 28.45ms; iter 3660: train loss 0.74321\n",
            "iter_dt 27.19ms; iter 3670: train loss 0.72504\n",
            "iter_dt 27.27ms; iter 3680: train loss 0.72960\n",
            "iter_dt 29.51ms; iter 3690: train loss 0.73864\n",
            "iter_dt 29.73ms; iter 3700: train loss 0.72998\n",
            "iter_dt 29.38ms; iter 3710: train loss 0.73865\n",
            "iter_dt 29.82ms; iter 3720: train loss 0.68638\n",
            "iter_dt 30.25ms; iter 3730: train loss 0.69304\n",
            "iter_dt 29.01ms; iter 3740: train loss 0.72091\n",
            "iter_dt 29.24ms; iter 3750: train loss 0.71469\n",
            "iter_dt 29.39ms; iter 3760: train loss 0.70152\n",
            "iter_dt 28.99ms; iter 3770: train loss 0.70647\n",
            "iter_dt 28.99ms; iter 3780: train loss 0.71059\n",
            "iter_dt 29.24ms; iter 3790: train loss 0.71398\n",
            "iter_dt 30.19ms; iter 3800: train loss 0.72696\n",
            "iter_dt 29.11ms; iter 3810: train loss 0.72343\n",
            "iter_dt 29.24ms; iter 3820: train loss 0.70280\n",
            "iter_dt 29.18ms; iter 3830: train loss 0.73202\n",
            "iter_dt 29.39ms; iter 3840: train loss 0.66817\n",
            "iter_dt 29.09ms; iter 3850: train loss 0.70935\n",
            "iter_dt 27.38ms; iter 3860: train loss 0.71476\n",
            "iter_dt 27.27ms; iter 3870: train loss 0.68162\n",
            "iter_dt 27.25ms; iter 3880: train loss 0.71255\n",
            "iter_dt 28.91ms; iter 3890: train loss 0.67429\n",
            "iter_dt 29.12ms; iter 3900: train loss 0.68444\n",
            "iter_dt 29.26ms; iter 3910: train loss 0.68864\n",
            "iter_dt 28.86ms; iter 3920: train loss 0.65284\n",
            "iter_dt 29.41ms; iter 3930: train loss 0.64432\n",
            "iter_dt 29.33ms; iter 3940: train loss 0.68882\n",
            "iter_dt 29.09ms; iter 3950: train loss 0.65385\n",
            "iter_dt 29.22ms; iter 3960: train loss 0.68554\n",
            "iter_dt 28.86ms; iter 3970: train loss 0.66674\n",
            "iter_dt 29.01ms; iter 3980: train loss 0.65223\n",
            "iter_dt 29.70ms; iter 3990: train loss 0.66941\n",
            "iter_dt 29.08ms; iter 4000: train loss 0.64808\n",
            "O God, O God! En misschien de kolen zouden. En tegen dat van hem\n",
            "noemden.\n",
            "\n",
            "Ze zat aan, die zei liep allemaal bij z'n boek was en zitten z'n schoenen tot\n",
            "zijn op een staart van en zoen. En als je zeilde Bavink met z'n hoofd af en m'n\n",
            "handen in de handen. \"Maat dien heeft is gezegd, hij wat heeft, daar iets voor\n",
            "is getrouwd.\" In de verten hoe z'n gezicht was en keek had me gezicht:\n",
            "\"Kal\", zei i, \"kan ik hardaar niet afscheid. Ik vond m'n vent was al ik\n",
            "een werk.\" Ik beschaf 't goed voor dat 't vertelijk wel. H\n",
            "saving model\n",
            "iter_dt 27.50ms; iter 4010: train loss 0.63110\n",
            "iter_dt 29.24ms; iter 4020: train loss 0.64052\n",
            "iter_dt 27.42ms; iter 4030: train loss 0.62698\n",
            "iter_dt 29.14ms; iter 4040: train loss 0.66675\n",
            "iter_dt 27.43ms; iter 4050: train loss 0.67524\n",
            "iter_dt 29.38ms; iter 4060: train loss 0.67080\n",
            "iter_dt 27.83ms; iter 4070: train loss 0.66072\n",
            "iter_dt 30.64ms; iter 4080: train loss 0.65731\n",
            "iter_dt 27.33ms; iter 4090: train loss 0.62311\n",
            "iter_dt 29.13ms; iter 4100: train loss 0.64623\n",
            "iter_dt 27.18ms; iter 4110: train loss 0.64666\n",
            "iter_dt 30.20ms; iter 4120: train loss 0.63693\n",
            "iter_dt 27.42ms; iter 4130: train loss 0.65828\n",
            "iter_dt 29.57ms; iter 4140: train loss 0.64011\n",
            "iter_dt 27.34ms; iter 4150: train loss 0.65389\n",
            "iter_dt 29.32ms; iter 4160: train loss 0.61249\n",
            "iter_dt 27.41ms; iter 4170: train loss 0.62810\n",
            "iter_dt 29.74ms; iter 4180: train loss 0.63243\n",
            "iter_dt 27.36ms; iter 4190: train loss 0.64157\n",
            "iter_dt 29.13ms; iter 4200: train loss 0.61354\n",
            "iter_dt 27.26ms; iter 4210: train loss 0.65774\n",
            "iter_dt 29.52ms; iter 4220: train loss 0.59367\n",
            "iter_dt 29.51ms; iter 4230: train loss 0.59574\n",
            "iter_dt 29.37ms; iter 4240: train loss 0.61708\n",
            "iter_dt 27.46ms; iter 4250: train loss 0.63235\n",
            "iter_dt 29.59ms; iter 4260: train loss 0.60131\n",
            "iter_dt 27.45ms; iter 4270: train loss 0.61859\n",
            "iter_dt 28.98ms; iter 4280: train loss 0.61178\n",
            "iter_dt 27.26ms; iter 4290: train loss 0.60332\n",
            "iter_dt 27.03ms; iter 4300: train loss 0.62012\n",
            "iter_dt 27.95ms; iter 4310: train loss 0.61050\n",
            "iter_dt 27.22ms; iter 4320: train loss 0.59278\n",
            "iter_dt 27.13ms; iter 4330: train loss 0.56970\n",
            "iter_dt 27.06ms; iter 4340: train loss 0.56873\n",
            "iter_dt 27.27ms; iter 4350: train loss 0.60408\n",
            "iter_dt 27.21ms; iter 4360: train loss 0.59292\n",
            "iter_dt 27.20ms; iter 4370: train loss 0.60080\n",
            "iter_dt 29.74ms; iter 4380: train loss 0.59738\n",
            "iter_dt 31.84ms; iter 4390: train loss 0.59095\n",
            "iter_dt 31.49ms; iter 4400: train loss 0.57213\n",
            "iter_dt 27.94ms; iter 4410: train loss 0.58545\n",
            "iter_dt 27.38ms; iter 4420: train loss 0.58775\n",
            "iter_dt 27.82ms; iter 4430: train loss 0.58351\n",
            "iter_dt 27.21ms; iter 4440: train loss 0.56988\n",
            "iter_dt 28.04ms; iter 4450: train loss 0.57395\n",
            "iter_dt 27.13ms; iter 4460: train loss 0.57044\n",
            "iter_dt 27.34ms; iter 4470: train loss 0.59389\n",
            "iter_dt 27.05ms; iter 4480: train loss 0.53587\n",
            "iter_dt 27.29ms; iter 4490: train loss 0.59566\n",
            "iter_dt 27.18ms; iter 4500: train loss 0.58124\n",
            "O God, O God! Alleen en den Dag heeft de\n",
            "speciaal heen, hij had een goed pijn moeite om haar kwam z'n bloote been in 't\n",
            "licht en ze zag er in, de koeien vreeselijk gehad, van de rails nooit\n",
            "van den kant van die, naar den beer, die geen dikke haar voeten in een\n",
            "anderenblauw en zoo hoe knappen, die telefen dat 's morgan op de den\n",
            "grond keek.\n",
            "\n",
            "\"Dag Coba wèren.\" Ik stond op de stad die anderen.\n",
            "\n",
            "'t Was heel gegaan, maar dat was lang genoeg. Hij kon wel nog eens lang\n",
            "worden. Als hij Daar zaten zei niets, hoorde i\n",
            "saving model\n",
            "iter_dt 27.09ms; iter 4510: train loss 0.57086\n",
            "iter_dt 27.09ms; iter 4520: train loss 0.55374\n",
            "iter_dt 29.07ms; iter 4530: train loss 0.59374\n",
            "iter_dt 27.11ms; iter 4540: train loss 0.55026\n",
            "iter_dt 27.30ms; iter 4550: train loss 0.55195\n",
            "iter_dt 27.35ms; iter 4560: train loss 0.54846\n",
            "iter_dt 27.62ms; iter 4570: train loss 0.56802\n",
            "iter_dt 27.47ms; iter 4580: train loss 0.55806\n",
            "iter_dt 27.68ms; iter 4590: train loss 0.59435\n",
            "iter_dt 27.96ms; iter 4600: train loss 0.55816\n",
            "iter_dt 27.36ms; iter 4610: train loss 0.54402\n",
            "iter_dt 27.51ms; iter 4620: train loss 0.55930\n",
            "iter_dt 27.38ms; iter 4630: train loss 0.56000\n",
            "iter_dt 27.45ms; iter 4640: train loss 0.56780\n",
            "iter_dt 27.81ms; iter 4650: train loss 0.53767\n",
            "iter_dt 28.36ms; iter 4660: train loss 0.56424\n",
            "iter_dt 27.36ms; iter 4670: train loss 0.55266\n",
            "iter_dt 27.78ms; iter 4680: train loss 0.55417\n",
            "iter_dt 27.52ms; iter 4690: train loss 0.54791\n",
            "iter_dt 28.31ms; iter 4700: train loss 0.55717\n",
            "iter_dt 29.07ms; iter 4710: train loss 0.51810\n",
            "iter_dt 29.11ms; iter 4720: train loss 0.53050\n",
            "iter_dt 27.19ms; iter 4730: train loss 0.54467\n",
            "iter_dt 27.54ms; iter 4740: train loss 0.53313\n",
            "iter_dt 29.77ms; iter 4750: train loss 0.53551\n",
            "iter_dt 28.93ms; iter 4760: train loss 0.54033\n",
            "iter_dt 29.34ms; iter 4770: train loss 0.55312\n",
            "iter_dt 28.99ms; iter 4780: train loss 0.53576\n",
            "iter_dt 29.22ms; iter 4790: train loss 0.53211\n",
            "iter_dt 29.04ms; iter 4800: train loss 0.49579\n",
            "iter_dt 29.03ms; iter 4810: train loss 0.55293\n",
            "iter_dt 28.74ms; iter 4820: train loss 0.51484\n",
            "iter_dt 28.85ms; iter 4830: train loss 0.51798\n",
            "iter_dt 28.86ms; iter 4840: train loss 0.51404\n",
            "iter_dt 27.18ms; iter 4850: train loss 0.50808\n",
            "iter_dt 27.48ms; iter 4860: train loss 0.52458\n",
            "iter_dt 27.36ms; iter 4870: train loss 0.52698\n",
            "iter_dt 29.03ms; iter 4880: train loss 0.52120\n",
            "iter_dt 29.02ms; iter 4890: train loss 0.53722\n",
            "iter_dt 28.82ms; iter 4900: train loss 0.53583\n",
            "iter_dt 28.98ms; iter 4910: train loss 0.53186\n",
            "iter_dt 28.90ms; iter 4920: train loss 0.53918\n",
            "iter_dt 29.06ms; iter 4930: train loss 0.53024\n",
            "iter_dt 28.76ms; iter 4940: train loss 0.50063\n",
            "iter_dt 29.08ms; iter 4950: train loss 0.50927\n",
            "iter_dt 29.27ms; iter 4960: train loss 0.51645\n",
            "iter_dt 28.98ms; iter 4970: train loss 0.52636\n",
            "iter_dt 29.25ms; iter 4980: train loss 0.50590\n",
            "iter_dt 28.95ms; iter 4990: train loss 0.52780\n",
            "iter_dt 28.97ms; iter 5000: train loss 0.50063\n",
            "O God, O God! En mijn een net of\n",
            "dat ons. Daar een mensch, in die dingen heer dan verdriettende.\n",
            "\n",
            "'t Dichtertje haar dichtte z'n dochtertje ziet zag 't keeren en zei:\n",
            "\"De rivier is trein is 't zoo zoo erg draaien, maar in een wit zanden met glas\n",
            "met een sombering taschje er in, slecht, die vriend niet te waalogkomen.\n",
            "\n",
            "Maar i daar met trekte i te zien keer naar 't Noordwesten, stille had gehoed,\n",
            "een goudgele malen duidelijk met 't delft beteekenen, grijn wit zijn oogheid had\n",
            "een belachelijk gezegd, dat er nie\n",
            "saving model\n",
            "iter_dt 28.96ms; iter 5010: train loss 0.53549\n",
            "iter_dt 27.13ms; iter 5020: train loss 0.50584\n",
            "iter_dt 29.36ms; iter 5030: train loss 0.50980\n",
            "iter_dt 27.60ms; iter 5040: train loss 0.46998\n",
            "iter_dt 29.18ms; iter 5050: train loss 0.51597\n",
            "iter_dt 27.46ms; iter 5060: train loss 0.52214\n",
            "iter_dt 29.06ms; iter 5070: train loss 0.50080\n",
            "iter_dt 27.41ms; iter 5080: train loss 0.52474\n",
            "iter_dt 29.52ms; iter 5090: train loss 0.47095\n",
            "iter_dt 27.40ms; iter 5100: train loss 0.50812\n",
            "iter_dt 29.33ms; iter 5110: train loss 0.50582\n",
            "iter_dt 28.33ms; iter 5120: train loss 0.48169\n",
            "iter_dt 29.06ms; iter 5130: train loss 0.50335\n",
            "iter_dt 27.34ms; iter 5140: train loss 0.49570\n",
            "iter_dt 29.38ms; iter 5150: train loss 0.49444\n",
            "iter_dt 27.18ms; iter 5160: train loss 0.48313\n",
            "iter_dt 29.18ms; iter 5170: train loss 0.52533\n",
            "iter_dt 27.31ms; iter 5180: train loss 0.49189\n",
            "iter_dt 29.01ms; iter 5190: train loss 0.50718\n",
            "iter_dt 27.69ms; iter 5200: train loss 0.49030\n",
            "iter_dt 27.52ms; iter 5210: train loss 0.48884\n",
            "iter_dt 27.35ms; iter 5220: train loss 0.49788\n",
            "iter_dt 27.30ms; iter 5230: train loss 0.50968\n",
            "iter_dt 27.20ms; iter 5240: train loss 0.46962\n",
            "iter_dt 29.63ms; iter 5250: train loss 0.46211\n",
            "iter_dt 27.14ms; iter 5260: train loss 0.49883\n",
            "iter_dt 29.36ms; iter 5270: train loss 0.51465\n",
            "iter_dt 27.09ms; iter 5280: train loss 0.46429\n",
            "iter_dt 27.40ms; iter 5290: train loss 0.47949\n",
            "iter_dt 27.27ms; iter 5300: train loss 0.48278\n",
            "iter_dt 29.23ms; iter 5310: train loss 0.51791\n",
            "iter_dt 27.11ms; iter 5320: train loss 0.48790\n",
            "iter_dt 29.38ms; iter 5330: train loss 0.48118\n",
            "iter_dt 27.51ms; iter 5340: train loss 0.48275\n",
            "iter_dt 29.31ms; iter 5350: train loss 0.50147\n",
            "iter_dt 27.00ms; iter 5360: train loss 0.47914\n",
            "iter_dt 29.64ms; iter 5370: train loss 0.47293\n",
            "iter_dt 27.68ms; iter 5380: train loss 0.48461\n",
            "iter_dt 28.96ms; iter 5390: train loss 0.48007\n",
            "iter_dt 27.28ms; iter 5400: train loss 0.46139\n",
            "iter_dt 29.25ms; iter 5410: train loss 0.46731\n",
            "iter_dt 27.08ms; iter 5420: train loss 0.46810\n",
            "iter_dt 27.16ms; iter 5430: train loss 0.47178\n",
            "iter_dt 27.10ms; iter 5440: train loss 0.48703\n",
            "iter_dt 27.21ms; iter 5450: train loss 0.47574\n",
            "iter_dt 27.16ms; iter 5460: train loss 0.46060\n",
            "iter_dt 27.51ms; iter 5470: train loss 0.46844\n",
            "iter_dt 27.26ms; iter 5480: train loss 0.43842\n",
            "iter_dt 28.38ms; iter 5490: train loss 0.45719\n",
            "iter_dt 27.17ms; iter 5500: train loss 0.46585\n",
            "O God, O God!\" En middag on-i ook heeft-i een\n",
            "betrekking van hun mijn sigaren op een papieren, en toen ik boven\n",
            "jelui de menschen om niet te houden. Ik ben ben de vrouw niet, maar\n",
            "mijn gedachten zijn geeft tusschen zijn kleeren verdroeg en een wonderlijk\n",
            "scht wend dan ons over uit den weg te lochten.\n",
            "\n",
            "Onderwijl schreef i op z'n zomermiddag waren gestapt en Bavink had aan\n",
            "gehad w. Z'n boekje leven van den groote gekosten voor dragen in 't huis\n",
            "en van de Waalt soliabolone tafee en er kreeg naar 't water en dan\n",
            "saving model\n",
            "iter_dt 27.15ms; iter 5510: train loss 0.45701\n",
            "iter_dt 27.15ms; iter 5520: train loss 0.44723\n",
            "iter_dt 27.02ms; iter 5530: train loss 0.44855\n",
            "iter_dt 27.11ms; iter 5540: train loss 0.45721\n",
            "iter_dt 26.99ms; iter 5550: train loss 0.43480\n",
            "iter_dt 27.19ms; iter 5560: train loss 0.45087\n",
            "iter_dt 27.25ms; iter 5570: train loss 0.46724\n",
            "iter_dt 27.15ms; iter 5580: train loss 0.45181\n",
            "iter_dt 28.35ms; iter 5590: train loss 0.44218\n",
            "iter_dt 27.14ms; iter 5600: train loss 0.44066\n",
            "iter_dt 27.10ms; iter 5610: train loss 0.45190\n",
            "iter_dt 27.12ms; iter 5620: train loss 0.43606\n",
            "iter_dt 27.13ms; iter 5630: train loss 0.46378\n",
            "iter_dt 28.46ms; iter 5640: train loss 0.47157\n",
            "iter_dt 27.30ms; iter 5650: train loss 0.46205\n",
            "iter_dt 29.23ms; iter 5660: train loss 0.43733\n",
            "iter_dt 27.23ms; iter 5670: train loss 0.45039\n",
            "iter_dt 29.14ms; iter 5680: train loss 0.45085\n",
            "iter_dt 27.21ms; iter 5690: train loss 0.46675\n",
            "iter_dt 29.40ms; iter 5700: train loss 0.45264\n",
            "iter_dt 27.28ms; iter 5710: train loss 0.43678\n",
            "iter_dt 29.11ms; iter 5720: train loss 0.43114\n",
            "iter_dt 28.17ms; iter 5730: train loss 0.43166\n",
            "iter_dt 29.26ms; iter 5740: train loss 0.41697\n",
            "iter_dt 27.58ms; iter 5750: train loss 0.44968\n",
            "iter_dt 28.40ms; iter 5760: train loss 0.46009\n",
            "iter_dt 27.32ms; iter 5770: train loss 0.43638\n",
            "iter_dt 28.29ms; iter 5780: train loss 0.42255\n",
            "iter_dt 27.61ms; iter 5790: train loss 0.42406\n",
            "iter_dt 29.10ms; iter 5800: train loss 0.43358\n",
            "iter_dt 27.20ms; iter 5810: train loss 0.43079\n",
            "iter_dt 27.18ms; iter 5820: train loss 0.42066\n",
            "iter_dt 27.26ms; iter 5830: train loss 0.43109\n",
            "iter_dt 26.97ms; iter 5840: train loss 0.45308\n",
            "iter_dt 27.25ms; iter 5850: train loss 0.41737\n",
            "iter_dt 27.40ms; iter 5860: train loss 0.44378\n",
            "iter_dt 28.93ms; iter 5870: train loss 0.44794\n",
            "iter_dt 27.33ms; iter 5880: train loss 0.44154\n",
            "iter_dt 27.17ms; iter 5890: train loss 0.43912\n",
            "iter_dt 27.88ms; iter 5900: train loss 0.43088\n",
            "iter_dt 27.12ms; iter 5910: train loss 0.45874\n",
            "iter_dt 27.80ms; iter 5920: train loss 0.44056\n",
            "iter_dt 27.23ms; iter 5930: train loss 0.42154\n",
            "iter_dt 27.61ms; iter 5940: train loss 0.42277\n",
            "iter_dt 27.28ms; iter 5950: train loss 0.44409\n",
            "iter_dt 28.24ms; iter 5960: train loss 0.43081\n",
            "iter_dt 28.08ms; iter 5970: train loss 0.42465\n",
            "iter_dt 27.94ms; iter 5980: train loss 0.42496\n",
            "iter_dt 28.82ms; iter 5990: train loss 0.41822\n",
            "iter_dt 28.13ms; iter 6000: train loss 0.41431\n",
            "O God, O God! Allemaal heeft heeft al niet veel te blauw,\n",
            "de branding roode strepen wat met vertelen, en zich aan, een lolletje Gods,\n",
            "datti zichzelf niet. Zijn wereld geleefd had, maar zij zal\n",
            "den niet zeggen niet zoen, hoor.   En dat begon toch een\n",
            "weinig kon. En dat dan niemand was mijn te lekker had en ontving\n",
            "de kleine had zachtjes weer gegloed. Ik keek naar haar de\n",
            "stoep rekte zich en zoo waren een tevreden menschen\n",
            "de milden weg, en hoe maakte, om toch de stoel er af. De rest van een langen aan zeilde\n",
            "\n",
            "saving model\n",
            "iter_dt 27.42ms; iter 6010: train loss 0.43628\n",
            "iter_dt 27.74ms; iter 6020: train loss 0.42614\n",
            "iter_dt 27.53ms; iter 6030: train loss 0.43104\n",
            "iter_dt 27.75ms; iter 6040: train loss 0.42082\n",
            "iter_dt 27.19ms; iter 6050: train loss 0.43630\n",
            "iter_dt 27.28ms; iter 6060: train loss 0.41524\n",
            "iter_dt 28.00ms; iter 6070: train loss 0.43840\n",
            "iter_dt 28.99ms; iter 6080: train loss 0.42259\n",
            "iter_dt 28.39ms; iter 6090: train loss 0.41960\n",
            "iter_dt 28.36ms; iter 6100: train loss 0.41982\n",
            "iter_dt 27.44ms; iter 6110: train loss 0.43650\n",
            "iter_dt 27.41ms; iter 6120: train loss 0.40391\n",
            "iter_dt 27.18ms; iter 6130: train loss 0.41055\n",
            "iter_dt 27.27ms; iter 6140: train loss 0.43079\n",
            "iter_dt 27.43ms; iter 6150: train loss 0.42048\n",
            "iter_dt 27.20ms; iter 6160: train loss 0.40084\n",
            "iter_dt 27.32ms; iter 6170: train loss 0.43307\n",
            "iter_dt 28.77ms; iter 6180: train loss 0.41153\n",
            "iter_dt 27.48ms; iter 6190: train loss 0.40501\n",
            "iter_dt 27.52ms; iter 6200: train loss 0.41510\n",
            "iter_dt 28.40ms; iter 6210: train loss 0.41648\n",
            "iter_dt 27.49ms; iter 6220: train loss 0.42972\n",
            "iter_dt 27.60ms; iter 6230: train loss 0.41477\n",
            "iter_dt 27.53ms; iter 6240: train loss 0.40467\n",
            "iter_dt 27.36ms; iter 6250: train loss 0.41642\n",
            "iter_dt 27.51ms; iter 6260: train loss 0.41881\n",
            "iter_dt 27.36ms; iter 6270: train loss 0.40551\n",
            "iter_dt 27.44ms; iter 6280: train loss 0.42951\n",
            "iter_dt 28.93ms; iter 6290: train loss 0.40202\n",
            "iter_dt 27.45ms; iter 6300: train loss 0.40341\n",
            "iter_dt 27.59ms; iter 6310: train loss 0.39608\n",
            "iter_dt 27.71ms; iter 6320: train loss 0.41367\n",
            "iter_dt 27.31ms; iter 6330: train loss 0.39875\n",
            "iter_dt 27.27ms; iter 6340: train loss 0.39367\n",
            "iter_dt 27.40ms; iter 6350: train loss 0.40640\n",
            "iter_dt 27.34ms; iter 6360: train loss 0.42313\n",
            "iter_dt 27.34ms; iter 6370: train loss 0.38989\n",
            "iter_dt 27.24ms; iter 6380: train loss 0.40570\n",
            "iter_dt 27.38ms; iter 6390: train loss 0.37694\n",
            "iter_dt 27.49ms; iter 6400: train loss 0.40648\n",
            "iter_dt 27.49ms; iter 6410: train loss 0.40852\n",
            "iter_dt 27.13ms; iter 6420: train loss 0.40761\n",
            "iter_dt 27.28ms; iter 6430: train loss 0.40194\n",
            "iter_dt 27.46ms; iter 6440: train loss 0.39058\n",
            "iter_dt 27.60ms; iter 6450: train loss 0.39413\n",
            "iter_dt 27.22ms; iter 6460: train loss 0.39556\n",
            "iter_dt 27.29ms; iter 6470: train loss 0.39949\n",
            "iter_dt 29.11ms; iter 6480: train loss 0.40812\n",
            "iter_dt 27.22ms; iter 6490: train loss 0.39428\n",
            "iter_dt 29.06ms; iter 6500: train loss 0.39963\n",
            "O God, O God! En\n",
            "maar op te tijden, ze allemaal had hebben. En zit eens hingstand ze zijn\n",
            "leven in één zomeravond. 't zonder Hoyer over keek naar geziend dat ook weer\n",
            "teruggeven.\" Maar om half pier nat achter 't blauw; de vrouw nu eens open ze hoe 't aanbrug. Dat\n",
            "ik was een wereld een dichtertje en welken zoo zwak. En wat waren\n",
            "we voor haar hoofdje was gebrand in haar hoofdje met haar roge boil en haar lieve groene\n",
            "schoenen aan. En begon moe hoe hoe 'n moeder wou en dat was er niet bij. 't Was\n",
            "doen moest ik \n",
            "saving model\n",
            "iter_dt 27.22ms; iter 6510: train loss 0.37587\n",
            "iter_dt 29.95ms; iter 6520: train loss 0.38751\n",
            "iter_dt 27.76ms; iter 6530: train loss 0.38332\n",
            "iter_dt 30.09ms; iter 6540: train loss 0.38202\n",
            "iter_dt 27.76ms; iter 6550: train loss 0.39723\n",
            "iter_dt 30.12ms; iter 6560: train loss 0.39049\n",
            "iter_dt 28.14ms; iter 6570: train loss 0.40613\n",
            "iter_dt 30.00ms; iter 6580: train loss 0.40953\n",
            "iter_dt 27.82ms; iter 6590: train loss 0.39429\n",
            "iter_dt 30.18ms; iter 6600: train loss 0.38825\n",
            "iter_dt 27.86ms; iter 6610: train loss 0.40448\n",
            "iter_dt 29.67ms; iter 6620: train loss 0.39283\n",
            "iter_dt 27.91ms; iter 6630: train loss 0.39229\n",
            "iter_dt 27.45ms; iter 6640: train loss 0.41897\n",
            "iter_dt 27.24ms; iter 6650: train loss 0.39112\n",
            "iter_dt 29.08ms; iter 6660: train loss 0.38832\n",
            "iter_dt 27.25ms; iter 6670: train loss 0.39165\n",
            "iter_dt 27.33ms; iter 6680: train loss 0.38868\n",
            "iter_dt 27.34ms; iter 6690: train loss 0.39390\n",
            "iter_dt 27.61ms; iter 6700: train loss 0.38379\n",
            "iter_dt 27.25ms; iter 6710: train loss 0.38493\n",
            "iter_dt 28.62ms; iter 6720: train loss 0.38857\n",
            "iter_dt 27.83ms; iter 6730: train loss 0.38829\n",
            "iter_dt 27.66ms; iter 6740: train loss 0.38732\n",
            "iter_dt 27.28ms; iter 6750: train loss 0.39403\n",
            "iter_dt 29.36ms; iter 6760: train loss 0.39820\n",
            "iter_dt 27.28ms; iter 6770: train loss 0.37523\n",
            "iter_dt 27.71ms; iter 6780: train loss 0.38083\n",
            "iter_dt 27.69ms; iter 6790: train loss 0.39520\n",
            "iter_dt 28.21ms; iter 6800: train loss 0.38904\n",
            "iter_dt 27.53ms; iter 6810: train loss 0.37647\n",
            "iter_dt 28.78ms; iter 6820: train loss 0.36735\n",
            "iter_dt 27.99ms; iter 6830: train loss 0.37079\n",
            "iter_dt 30.08ms; iter 6840: train loss 0.37923\n",
            "iter_dt 27.81ms; iter 6850: train loss 0.37847\n",
            "iter_dt 29.92ms; iter 6860: train loss 0.38593\n",
            "iter_dt 27.15ms; iter 6870: train loss 0.37251\n",
            "iter_dt 29.54ms; iter 6880: train loss 0.40291\n",
            "iter_dt 28.48ms; iter 6890: train loss 0.38698\n",
            "iter_dt 29.06ms; iter 6900: train loss 0.37499\n",
            "iter_dt 27.23ms; iter 6910: train loss 0.36944\n",
            "iter_dt 27.26ms; iter 6920: train loss 0.38432\n",
            "iter_dt 27.24ms; iter 6930: train loss 0.37466\n",
            "iter_dt 27.32ms; iter 6940: train loss 0.37425\n",
            "iter_dt 27.33ms; iter 6950: train loss 0.37956\n",
            "iter_dt 27.85ms; iter 6960: train loss 0.40021\n",
            "iter_dt 27.48ms; iter 6970: train loss 0.38130\n",
            "iter_dt 27.19ms; iter 6980: train loss 0.36524\n",
            "iter_dt 27.29ms; iter 6990: train loss 0.38612\n",
            "iter_dt 27.28ms; iter 7000: train loss 0.39086\n",
            "O God, O God! DISS ANY DIRESS BUT OF SUCH OF DISTRIBUTOR UNDER                                                        NESCIO.\n",
            "\n",
            "5 Jan. 1918.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "EEn of Project Gutenberg-tm electronic works in accordance\n",
            "with this agreement, and any how your work or any compilation of a part of this work\n",
            "(or any computers.  If any discovert indicate that you all work other any Project\n",
            "Gutenberg-tm electronic work, you indicate the person or entity that provided\n",
            "with the defective work may electronic works\n",
            "by the people\n",
            "saving model\n",
            "iter_dt 27.05ms; iter 7010: train loss 0.39511\n",
            "iter_dt 27.04ms; iter 7020: train loss 0.36942\n",
            "iter_dt 27.06ms; iter 7030: train loss 0.37890\n",
            "iter_dt 27.28ms; iter 7040: train loss 0.35549\n",
            "iter_dt 27.31ms; iter 7050: train loss 0.37020\n",
            "iter_dt 27.41ms; iter 7060: train loss 0.34099\n",
            "iter_dt 27.40ms; iter 7070: train loss 0.38167\n",
            "iter_dt 27.61ms; iter 7080: train loss 0.37325\n",
            "iter_dt 27.30ms; iter 7090: train loss 0.38191\n",
            "iter_dt 28.91ms; iter 7100: train loss 0.35373\n",
            "iter_dt 27.36ms; iter 7110: train loss 0.38427\n",
            "iter_dt 29.02ms; iter 7120: train loss 0.37811\n",
            "iter_dt 27.20ms; iter 7130: train loss 0.36715\n",
            "iter_dt 29.22ms; iter 7140: train loss 0.37374\n",
            "iter_dt 27.19ms; iter 7150: train loss 0.35043\n",
            "iter_dt 29.07ms; iter 7160: train loss 0.37862\n",
            "iter_dt 27.21ms; iter 7170: train loss 0.36804\n",
            "iter_dt 29.06ms; iter 7180: train loss 0.37670\n",
            "iter_dt 27.34ms; iter 7190: train loss 0.37281\n",
            "iter_dt 29.44ms; iter 7200: train loss 0.36319\n",
            "iter_dt 28.04ms; iter 7210: train loss 0.34853\n",
            "iter_dt 29.49ms; iter 7220: train loss 0.36449\n",
            "iter_dt 27.41ms; iter 7230: train loss 0.36039\n",
            "iter_dt 29.34ms; iter 7240: train loss 0.35794\n",
            "iter_dt 27.29ms; iter 7250: train loss 0.36371\n",
            "iter_dt 29.65ms; iter 7260: train loss 0.35561\n",
            "iter_dt 27.67ms; iter 7270: train loss 0.35786\n",
            "iter_dt 29.28ms; iter 7280: train loss 0.35507\n",
            "iter_dt 27.50ms; iter 7290: train loss 0.35678\n",
            "iter_dt 29.69ms; iter 7300: train loss 0.35897\n",
            "iter_dt 27.38ms; iter 7310: train loss 0.37747\n",
            "iter_dt 29.33ms; iter 7320: train loss 0.35538\n",
            "iter_dt 27.21ms; iter 7330: train loss 0.34493\n",
            "iter_dt 29.72ms; iter 7340: train loss 0.35286\n",
            "iter_dt 27.85ms; iter 7350: train loss 0.37902\n",
            "iter_dt 29.45ms; iter 7360: train loss 0.36251\n",
            "iter_dt 27.70ms; iter 7370: train loss 0.35545\n",
            "iter_dt 27.46ms; iter 7380: train loss 0.34764\n",
            "iter_dt 27.21ms; iter 7390: train loss 0.36125\n",
            "iter_dt 29.15ms; iter 7400: train loss 0.37797\n",
            "iter_dt 27.36ms; iter 7410: train loss 0.35709\n",
            "iter_dt 27.24ms; iter 7420: train loss 0.34345\n",
            "iter_dt 27.15ms; iter 7430: train loss 0.37786\n",
            "iter_dt 27.13ms; iter 7440: train loss 0.36335\n",
            "iter_dt 27.51ms; iter 7450: train loss 0.36093\n",
            "iter_dt 27.25ms; iter 7460: train loss 0.36485\n",
            "iter_dt 27.33ms; iter 7470: train loss 0.34543\n",
            "iter_dt 27.19ms; iter 7480: train loss 0.34792\n",
            "iter_dt 27.28ms; iter 7490: train loss 0.35316\n",
            "iter_dt 28.15ms; iter 7500: train loss 0.34373\n",
            "O God, O God! Nederland heeft hemel in Parijs getracteerd en Japi\n",
            "had al die solicitation of verstaat boven, met nu sprong op en nam vijfel\n",
            "gemaakt en een ons, waar kwart over een versche gulde pijp\n",
            "van haar stuiven. De koeien, de op wat groene\n",
            "te kijken en trekken vervelende gezichtjes geven omdat 't altijd in 't\n",
            "gezeten van de \"Nieuwe Karseboom van Appi.\" \"Waarom moest ik toch op die tram?\"\n",
            "\n",
            "Dien middag maakte Bekker z'n eerste gedicht. En toen ik met 't\n",
            "aansteken van de gaslantarens in Leiden aankwam en d\n",
            "saving model\n",
            "iter_dt 27.16ms; iter 7510: train loss 0.34286\n",
            "iter_dt 27.69ms; iter 7520: train loss 0.36850\n",
            "iter_dt 27.27ms; iter 7530: train loss 0.35998\n",
            "iter_dt 27.34ms; iter 7540: train loss 0.35148\n",
            "iter_dt 27.28ms; iter 7550: train loss 0.35816\n",
            "iter_dt 27.26ms; iter 7560: train loss 0.35592\n",
            "iter_dt 27.26ms; iter 7570: train loss 0.34853\n",
            "iter_dt 27.31ms; iter 7580: train loss 0.34543\n",
            "iter_dt 27.45ms; iter 7590: train loss 0.34917\n",
            "iter_dt 27.40ms; iter 7600: train loss 0.34220\n",
            "iter_dt 27.47ms; iter 7610: train loss 0.35451\n",
            "iter_dt 27.40ms; iter 7620: train loss 0.35637\n",
            "iter_dt 27.33ms; iter 7630: train loss 0.34423\n",
            "iter_dt 27.43ms; iter 7640: train loss 0.34827\n",
            "iter_dt 27.36ms; iter 7650: train loss 0.33871\n",
            "iter_dt 27.41ms; iter 7660: train loss 0.35779\n",
            "iter_dt 27.59ms; iter 7670: train loss 0.36889\n",
            "iter_dt 28.15ms; iter 7680: train loss 0.35596\n",
            "iter_dt 27.58ms; iter 7690: train loss 0.35404\n",
            "iter_dt 27.46ms; iter 7700: train loss 0.34473\n",
            "iter_dt 27.35ms; iter 7710: train loss 0.34587\n",
            "iter_dt 27.52ms; iter 7720: train loss 0.34726\n",
            "iter_dt 27.27ms; iter 7730: train loss 0.35786\n",
            "iter_dt 27.35ms; iter 7740: train loss 0.36170\n",
            "iter_dt 27.25ms; iter 7750: train loss 0.34135\n",
            "iter_dt 27.52ms; iter 7760: train loss 0.33833\n",
            "iter_dt 27.61ms; iter 7770: train loss 0.34845\n",
            "iter_dt 27.29ms; iter 7780: train loss 0.34052\n",
            "iter_dt 27.28ms; iter 7790: train loss 0.35112\n",
            "iter_dt 27.38ms; iter 7800: train loss 0.35335\n",
            "iter_dt 27.98ms; iter 7810: train loss 0.35096\n",
            "iter_dt 27.45ms; iter 7820: train loss 0.33425\n",
            "iter_dt 28.15ms; iter 7830: train loss 0.32454\n",
            "iter_dt 28.17ms; iter 7840: train loss 0.34556\n",
            "iter_dt 28.40ms; iter 7850: train loss 0.34910\n",
            "iter_dt 27.88ms; iter 7860: train loss 0.33334\n",
            "iter_dt 28.47ms; iter 7870: train loss 0.34743\n",
            "iter_dt 27.30ms; iter 7880: train loss 0.35373\n",
            "iter_dt 27.80ms; iter 7890: train loss 0.33125\n",
            "iter_dt 27.22ms; iter 7900: train loss 0.36095\n",
            "iter_dt 27.52ms; iter 7910: train loss 0.33958\n",
            "iter_dt 27.41ms; iter 7920: train loss 0.34042\n",
            "iter_dt 27.78ms; iter 7930: train loss 0.33590\n",
            "iter_dt 27.21ms; iter 7940: train loss 0.31546\n",
            "iter_dt 28.42ms; iter 7950: train loss 0.31188\n",
            "iter_dt 27.10ms; iter 7960: train loss 0.32690\n",
            "iter_dt 27.34ms; iter 7970: train loss 0.34815\n",
            "iter_dt 27.19ms; iter 7980: train loss 0.33494\n",
            "iter_dt 27.45ms; iter 7990: train loss 0.34501\n",
            "iter_dt 27.07ms; iter 8000: train loss 0.33945\n",
            "O God, O God! Datt. Dat is een nauwen het verkocht in de punton-ster\n",
            "een lijne weer op den top. De aardige straat land\".\n",
            "\n",
            "Wat wil ze er bijna van elkaar en had ze bij elkaar en zoo zal\n",
            "'t witte blauwe oogen en hield aldoor z'n pet vast. Meteen\n",
            "kwam er een plof van hooge boomen, de kraag. Nu hij zei: \"Weet jij een\n",
            "vind ik geluk dat,\" kan maar dat maar aan één keken op lief de heuvels van\n",
            "'t witte straat te stillen, bekende vlekken, rondderde en donkere bankink\n",
            "met steiger op een schrift, maar kant naar de luc\n",
            "saving model\n",
            "iter_dt 29.06ms; iter 8010: train loss 0.34371\n",
            "iter_dt 29.18ms; iter 8020: train loss 0.34082\n",
            "iter_dt 28.14ms; iter 8030: train loss 0.34270\n",
            "iter_dt 29.70ms; iter 8040: train loss 0.36324\n",
            "iter_dt 28.86ms; iter 8050: train loss 0.33105\n",
            "iter_dt 27.80ms; iter 8060: train loss 0.34705\n",
            "iter_dt 28.01ms; iter 8070: train loss 0.33111\n",
            "iter_dt 28.05ms; iter 8080: train loss 0.33687\n",
            "iter_dt 27.83ms; iter 8090: train loss 0.34924\n",
            "iter_dt 28.14ms; iter 8100: train loss 0.34421\n",
            "iter_dt 27.11ms; iter 8110: train loss 0.33939\n",
            "iter_dt 27.24ms; iter 8120: train loss 0.33689\n",
            "iter_dt 27.84ms; iter 8130: train loss 0.34503\n",
            "iter_dt 27.32ms; iter 8140: train loss 0.34241\n",
            "iter_dt 27.55ms; iter 8150: train loss 0.33270\n",
            "iter_dt 27.61ms; iter 8160: train loss 0.34118\n",
            "iter_dt 27.28ms; iter 8170: train loss 0.34091\n",
            "iter_dt 28.67ms; iter 8180: train loss 0.31097\n",
            "iter_dt 27.73ms; iter 8190: train loss 0.34056\n",
            "iter_dt 27.75ms; iter 8200: train loss 0.33036\n",
            "iter_dt 27.65ms; iter 8210: train loss 0.32706\n",
            "iter_dt 28.46ms; iter 8220: train loss 0.34336\n",
            "iter_dt 27.32ms; iter 8230: train loss 0.33684\n",
            "iter_dt 28.83ms; iter 8240: train loss 0.32956\n",
            "iter_dt 27.98ms; iter 8250: train loss 0.33613\n",
            "iter_dt 28.33ms; iter 8260: train loss 0.33158\n",
            "iter_dt 28.04ms; iter 8270: train loss 0.32809\n",
            "iter_dt 28.16ms; iter 8280: train loss 0.33339\n",
            "iter_dt 28.05ms; iter 8290: train loss 0.32567\n",
            "iter_dt 27.57ms; iter 8300: train loss 0.32608\n",
            "iter_dt 27.83ms; iter 8310: train loss 0.32698\n",
            "iter_dt 27.87ms; iter 8320: train loss 0.32453\n",
            "iter_dt 27.88ms; iter 8330: train loss 0.33163\n",
            "iter_dt 27.94ms; iter 8340: train loss 0.32539\n",
            "iter_dt 27.32ms; iter 8350: train loss 0.32885\n",
            "iter_dt 28.79ms; iter 8360: train loss 0.31436\n",
            "iter_dt 27.38ms; iter 8370: train loss 0.31353\n",
            "iter_dt 27.36ms; iter 8380: train loss 0.32151\n",
            "iter_dt 28.04ms; iter 8390: train loss 0.33609\n",
            "iter_dt 27.63ms; iter 8400: train loss 0.34581\n",
            "iter_dt 27.71ms; iter 8410: train loss 0.31158\n",
            "iter_dt 28.56ms; iter 8420: train loss 0.33251\n",
            "iter_dt 28.24ms; iter 8430: train loss 0.32833\n",
            "iter_dt 29.17ms; iter 8440: train loss 0.32451\n",
            "iter_dt 28.65ms; iter 8450: train loss 0.31911\n",
            "iter_dt 28.34ms; iter 8460: train loss 0.31216\n",
            "iter_dt 28.64ms; iter 8470: train loss 0.34245\n",
            "iter_dt 28.10ms; iter 8480: train loss 0.33922\n",
            "iter_dt 28.95ms; iter 8490: train loss 0.34551\n",
            "iter_dt 28.07ms; iter 8500: train loss 0.32637\n",
            "O God, O God! En\n",
            "Nederland warel er bij een half zagen 't gras en Zondag.\n",
            "\n",
            "De stad i op 't gras of i ook zoo niet goed keek zien en daarna stapten en trok al leggen:\n",
            "\"Le Lys dans la Vallée\" van Balzac. \"Aha, Balzac. Geen kwajongen,\n",
            "die oue heer. Dood hè? Al lang dood. Natuurlijk. Waar kom je vandaan,\n",
            "Hoyer? Wat heb je daar een mooie jas aan. Ga eens staan. Te kort,\n",
            "kerel, veel te kort\". Bavink was genoegerig. \"Dat weet ik potdome\n",
            "onsank\", zei Japi, \"vooruit daar komt om jouwe hebben. Japi wist nu er over\n",
            "dac\n",
            "saving model\n",
            "iter_dt 29.41ms; iter 8510: train loss 0.32798\n",
            "iter_dt 28.29ms; iter 8520: train loss 0.31928\n",
            "iter_dt 27.50ms; iter 8530: train loss 0.32264\n",
            "iter_dt 27.94ms; iter 8540: train loss 0.32797\n",
            "iter_dt 27.83ms; iter 8550: train loss 0.32030\n",
            "iter_dt 27.32ms; iter 8560: train loss 0.32440\n",
            "iter_dt 28.05ms; iter 8570: train loss 0.31343\n",
            "iter_dt 28.37ms; iter 8580: train loss 0.32246\n",
            "iter_dt 28.09ms; iter 8590: train loss 0.33077\n",
            "iter_dt 27.56ms; iter 8600: train loss 0.32194\n",
            "iter_dt 27.88ms; iter 8610: train loss 0.33074\n",
            "iter_dt 27.77ms; iter 8620: train loss 0.34161\n",
            "iter_dt 27.86ms; iter 8630: train loss 0.31948\n",
            "iter_dt 28.10ms; iter 8640: train loss 0.31268\n",
            "iter_dt 27.81ms; iter 8650: train loss 0.31492\n",
            "iter_dt 27.76ms; iter 8660: train loss 0.31856\n",
            "iter_dt 27.64ms; iter 8670: train loss 0.32225\n",
            "iter_dt 27.34ms; iter 8680: train loss 0.32369\n",
            "iter_dt 27.61ms; iter 8690: train loss 0.32742\n",
            "iter_dt 27.50ms; iter 8700: train loss 0.32280\n",
            "iter_dt 27.49ms; iter 8710: train loss 0.31850\n",
            "iter_dt 27.45ms; iter 8720: train loss 0.30723\n",
            "iter_dt 27.69ms; iter 8730: train loss 0.32627\n",
            "iter_dt 27.47ms; iter 8740: train loss 0.33511\n",
            "iter_dt 27.54ms; iter 8750: train loss 0.31422\n",
            "iter_dt 27.80ms; iter 8760: train loss 0.31139\n",
            "iter_dt 27.63ms; iter 8770: train loss 0.32421\n",
            "iter_dt 27.87ms; iter 8780: train loss 0.30936\n",
            "iter_dt 27.59ms; iter 8790: train loss 0.31708\n",
            "iter_dt 27.67ms; iter 8800: train loss 0.33393\n",
            "iter_dt 27.83ms; iter 8810: train loss 0.31548\n",
            "iter_dt 28.00ms; iter 8820: train loss 0.31087\n",
            "iter_dt 27.35ms; iter 8830: train loss 0.33413\n",
            "iter_dt 27.28ms; iter 8840: train loss 0.30721\n",
            "iter_dt 27.78ms; iter 8850: train loss 0.32562\n",
            "iter_dt 27.58ms; iter 8860: train loss 0.31236\n",
            "iter_dt 27.97ms; iter 8870: train loss 0.30155\n",
            "iter_dt 27.86ms; iter 8880: train loss 0.31774\n",
            "iter_dt 28.48ms; iter 8890: train loss 0.31470\n",
            "iter_dt 28.46ms; iter 8900: train loss 0.32393\n",
            "iter_dt 30.16ms; iter 8910: train loss 0.31663\n",
            "iter_dt 28.08ms; iter 8920: train loss 0.31982\n",
            "iter_dt 29.69ms; iter 8930: train loss 0.31326\n",
            "iter_dt 27.39ms; iter 8940: train loss 0.30878\n",
            "iter_dt 28.65ms; iter 8950: train loss 0.31855\n",
            "iter_dt 27.78ms; iter 8960: train loss 0.30511\n",
            "iter_dt 28.30ms; iter 8970: train loss 0.30975\n",
            "iter_dt 27.83ms; iter 8980: train loss 0.32989\n",
            "iter_dt 28.00ms; iter 8990: train loss 0.32015\n",
            "iter_dt 28.21ms; iter 9000: train loss 0.31477\n",
            "O God, O God! Van Nederland, van heel Nederland,\n",
            "van Surhuisterveen en Spekholzerheide, donateur van den Bond van hoofden\n",
            "snorden gestorven was. De sloeg weer den overkant ter was en dacht i. Nu zie eerbiedwaardig\n",
            "hoofd en ze teekende staren voor zich 't huis aan den kin naar den grond\n",
            "en staar en keken naar 't gespren hemoten. En dan gaven kwam i de koeien\n",
            "langen op de hei zou om komen aan den overkant ter werken. \"Klappen\", zei Japi. En\n",
            "bleek in dat 't gebeurde. Bavink kerel. Denk grosste stilletjes. De\n",
            "Go\n",
            "saving model\n",
            "iter_dt 27.27ms; iter 9010: train loss 0.31590\n",
            "iter_dt 27.93ms; iter 9020: train loss 0.30692\n",
            "iter_dt 27.37ms; iter 9030: train loss 0.31170\n",
            "iter_dt 27.12ms; iter 9040: train loss 0.30725\n",
            "iter_dt 27.51ms; iter 9050: train loss 0.32255\n",
            "iter_dt 27.47ms; iter 9060: train loss 0.30738\n",
            "iter_dt 27.28ms; iter 9070: train loss 0.31858\n",
            "iter_dt 29.05ms; iter 9080: train loss 0.32125\n",
            "iter_dt 26.96ms; iter 9090: train loss 0.30076\n",
            "iter_dt 27.47ms; iter 9100: train loss 0.31983\n",
            "iter_dt 27.13ms; iter 9110: train loss 0.29231\n",
            "iter_dt 27.40ms; iter 9120: train loss 0.30833\n",
            "iter_dt 27.32ms; iter 9130: train loss 0.30966\n",
            "iter_dt 28.80ms; iter 9140: train loss 0.29667\n",
            "iter_dt 27.14ms; iter 9150: train loss 0.30917\n",
            "iter_dt 27.54ms; iter 9160: train loss 0.29621\n",
            "iter_dt 27.22ms; iter 9170: train loss 0.32687\n",
            "iter_dt 27.62ms; iter 9180: train loss 0.30666\n",
            "iter_dt 27.30ms; iter 9190: train loss 0.30836\n",
            "iter_dt 27.64ms; iter 9200: train loss 0.31190\n",
            "iter_dt 28.81ms; iter 9210: train loss 0.30812\n",
            "iter_dt 27.44ms; iter 9220: train loss 0.31787\n",
            "iter_dt 27.60ms; iter 9230: train loss 0.31131\n",
            "iter_dt 27.41ms; iter 9240: train loss 0.30305\n",
            "iter_dt 27.39ms; iter 9250: train loss 0.30611\n",
            "iter_dt 27.50ms; iter 9260: train loss 0.31087\n",
            "iter_dt 27.54ms; iter 9270: train loss 0.31302\n",
            "iter_dt 27.96ms; iter 9280: train loss 0.30310\n",
            "iter_dt 27.49ms; iter 9290: train loss 0.31052\n",
            "iter_dt 27.85ms; iter 9300: train loss 0.30725\n",
            "iter_dt 27.88ms; iter 9310: train loss 0.32232\n",
            "iter_dt 27.58ms; iter 9320: train loss 0.31355\n",
            "iter_dt 27.24ms; iter 9330: train loss 0.30376\n",
            "iter_dt 27.58ms; iter 9340: train loss 0.32831\n",
            "iter_dt 27.79ms; iter 9350: train loss 0.30050\n",
            "iter_dt 28.22ms; iter 9360: train loss 0.31218\n",
            "iter_dt 27.75ms; iter 9370: train loss 0.30949\n",
            "iter_dt 27.59ms; iter 9380: train loss 0.31807\n",
            "iter_dt 27.51ms; iter 9390: train loss 0.30363\n",
            "iter_dt 27.42ms; iter 9400: train loss 0.28648\n",
            "iter_dt 29.41ms; iter 9410: train loss 0.30423\n",
            "iter_dt 27.34ms; iter 9420: train loss 0.30447\n",
            "iter_dt 27.55ms; iter 9430: train loss 0.30512\n",
            "iter_dt 27.64ms; iter 9440: train loss 0.32092\n",
            "iter_dt 27.74ms; iter 9450: train loss 0.30561\n",
            "iter_dt 27.72ms; iter 9460: train loss 0.30064\n",
            "iter_dt 27.75ms; iter 9470: train loss 0.30740\n",
            "iter_dt 27.68ms; iter 9480: train loss 0.31049\n",
            "iter_dt 28.78ms; iter 9490: train loss 0.30723\n",
            "iter_dt 27.98ms; iter 9500: train loss 0.30206\n",
            "O God, O God! Van te reis terug, waar ze zullen ophouden, dat zie\n",
            "je niet en daar denk je niet over. 't Was heel aardig en misschien\n",
            "waren ze nog maar pas verloofd en tevreden met elkaar vast te houden\n",
            "en te dwepen. Toen keken ze elkaar om dacht haar kindje hatti geknipt was,\n",
            "ze dwaas de dood geweld, een rood licht was opgestoken en daarnaast van z'n handen in z'n\n",
            "dichterhoofd. De kamer was half donker. Hij bewoog niet, maar er niets\n",
            "komt meer, gebnneven.\" Even de donkere menschen,\n",
            "die de gedichten trok naar\n",
            "saving model\n",
            "iter_dt 27.72ms; iter 9510: train loss 0.30733\n",
            "iter_dt 27.70ms; iter 9520: train loss 0.30823\n",
            "iter_dt 27.57ms; iter 9530: train loss 0.29335\n",
            "iter_dt 28.12ms; iter 9540: train loss 0.32079\n",
            "iter_dt 27.68ms; iter 9550: train loss 0.30551\n",
            "iter_dt 27.38ms; iter 9560: train loss 0.28386\n",
            "iter_dt 29.10ms; iter 9570: train loss 0.29530\n",
            "iter_dt 27.35ms; iter 9580: train loss 0.30483\n",
            "iter_dt 28.04ms; iter 9590: train loss 0.30123\n",
            "iter_dt 27.47ms; iter 9600: train loss 0.30273\n",
            "iter_dt 27.29ms; iter 9610: train loss 0.30388\n",
            "iter_dt 28.15ms; iter 9620: train loss 0.30566\n",
            "iter_dt 27.94ms; iter 9630: train loss 0.31889\n",
            "iter_dt 27.67ms; iter 9640: train loss 0.30386\n",
            "iter_dt 27.60ms; iter 9650: train loss 0.28207\n",
            "iter_dt 27.74ms; iter 9660: train loss 0.29795\n",
            "iter_dt 27.96ms; iter 9670: train loss 0.30756\n",
            "iter_dt 28.99ms; iter 9680: train loss 0.29223\n",
            "iter_dt 29.25ms; iter 9690: train loss 0.30790\n",
            "iter_dt 27.66ms; iter 9700: train loss 0.30442\n",
            "iter_dt 28.04ms; iter 9710: train loss 0.31419\n",
            "iter_dt 28.00ms; iter 9720: train loss 0.28164\n",
            "iter_dt 27.91ms; iter 9730: train loss 0.31053\n",
            "iter_dt 29.12ms; iter 9740: train loss 0.30134\n",
            "iter_dt 28.37ms; iter 9750: train loss 0.31998\n",
            "iter_dt 27.42ms; iter 9760: train loss 0.28650\n",
            "iter_dt 27.62ms; iter 9770: train loss 0.29943\n",
            "iter_dt 27.55ms; iter 9780: train loss 0.30227\n",
            "iter_dt 28.34ms; iter 9790: train loss 0.30237\n",
            "iter_dt 28.25ms; iter 9800: train loss 0.30902\n",
            "iter_dt 28.07ms; iter 9810: train loss 0.29294\n",
            "iter_dt 27.84ms; iter 9820: train loss 0.29703\n",
            "iter_dt 27.24ms; iter 9830: train loss 0.29680\n",
            "iter_dt 27.38ms; iter 9840: train loss 0.31403\n",
            "iter_dt 27.96ms; iter 9850: train loss 0.29781\n",
            "iter_dt 27.26ms; iter 9860: train loss 0.30431\n",
            "iter_dt 27.40ms; iter 9870: train loss 0.30753\n",
            "iter_dt 28.66ms; iter 9880: train loss 0.29776\n",
            "iter_dt 27.44ms; iter 9890: train loss 0.29389\n",
            "iter_dt 27.25ms; iter 9900: train loss 0.29043\n",
            "iter_dt 27.42ms; iter 9910: train loss 0.28687\n",
            "iter_dt 29.30ms; iter 9920: train loss 0.29201\n",
            "iter_dt 27.16ms; iter 9930: train loss 0.30357\n",
            "iter_dt 29.10ms; iter 9940: train loss 0.29438\n",
            "iter_dt 27.12ms; iter 9950: train loss 0.28732\n",
            "iter_dt 29.06ms; iter 9960: train loss 0.28972\n",
            "iter_dt 28.36ms; iter 9970: train loss 0.29774\n",
            "iter_dt 29.96ms; iter 9980: train loss 0.31260\n",
            "iter_dt 29.60ms; iter 9990: train loss 0.29132\n",
            "iter_dt 27.11ms; iter 10000: train loss 0.29638\n",
            "O God, O God! Handelsblad\n",
            "en verheen, die God weet hoe heel niet gekocht bij hem zouden. Dat vonden ze ook weer niet\n",
            "goed. Nooit had ons Lieve Heer daar vroeger iets bij gedacht. En nu\n",
            "hatti kwestie. 't Was begonnen met versjes over \"wetende oogen.\" Toen\n",
            "zei er één, dat 't allemaal bedrog was, een vroom bedrog van God. Godverten en direct\n",
            "van hen, zie diep en bij nacht samen rondscharrelden, dat ze gezien had\n",
            "en gekeken, als i een dichtertje in haar beide handen en hief\n",
            "haar ten vormen en naar de oniging. De\n",
            "saving model\n",
            "iter_dt 29.01ms; iter 10010: train loss 0.28366\n",
            "iter_dt 27.08ms; iter 10020: train loss 0.30228\n",
            "iter_dt 29.25ms; iter 10030: train loss 0.30040\n",
            "iter_dt 27.25ms; iter 10040: train loss 0.28808\n",
            "iter_dt 29.63ms; iter 10050: train loss 0.29995\n",
            "iter_dt 27.29ms; iter 10060: train loss 0.29576\n",
            "iter_dt 29.23ms; iter 10070: train loss 0.29327\n",
            "iter_dt 28.08ms; iter 10080: train loss 0.28887\n",
            "iter_dt 27.39ms; iter 10090: train loss 0.29812\n",
            "iter_dt 27.18ms; iter 10100: train loss 0.29570\n",
            "iter_dt 27.24ms; iter 10110: train loss 0.30533\n",
            "iter_dt 27.16ms; iter 10120: train loss 0.28215\n",
            "iter_dt 27.13ms; iter 10130: train loss 0.29483\n",
            "iter_dt 27.32ms; iter 10140: train loss 0.28851\n",
            "iter_dt 27.37ms; iter 10150: train loss 0.28532\n",
            "iter_dt 27.40ms; iter 10160: train loss 0.28978\n",
            "iter_dt 27.61ms; iter 10170: train loss 0.29415\n",
            "iter_dt 27.17ms; iter 10180: train loss 0.27951\n",
            "iter_dt 27.83ms; iter 10190: train loss 0.29238\n",
            "iter_dt 28.62ms; iter 10200: train loss 0.28635\n",
            "iter_dt 27.56ms; iter 10210: train loss 0.29596\n",
            "iter_dt 27.65ms; iter 10220: train loss 0.27896\n",
            "iter_dt 28.24ms; iter 10230: train loss 0.29725\n",
            "iter_dt 28.19ms; iter 10240: train loss 0.29709\n",
            "iter_dt 27.42ms; iter 10250: train loss 0.28532\n",
            "iter_dt 27.31ms; iter 10260: train loss 0.28909\n",
            "iter_dt 27.43ms; iter 10270: train loss 0.28725\n",
            "iter_dt 27.52ms; iter 10280: train loss 0.28691\n",
            "iter_dt 28.18ms; iter 10290: train loss 0.28613\n",
            "iter_dt 27.28ms; iter 10300: train loss 0.29121\n",
            "iter_dt 27.21ms; iter 10310: train loss 0.30120\n",
            "iter_dt 27.48ms; iter 10320: train loss 0.28919\n",
            "iter_dt 27.50ms; iter 10330: train loss 0.29299\n",
            "iter_dt 27.27ms; iter 10340: train loss 0.29255\n",
            "iter_dt 27.29ms; iter 10350: train loss 0.29178\n",
            "iter_dt 27.43ms; iter 10360: train loss 0.29303\n",
            "iter_dt 28.29ms; iter 10370: train loss 0.27702\n",
            "iter_dt 28.17ms; iter 10380: train loss 0.27669\n",
            "iter_dt 28.14ms; iter 10390: train loss 0.28751\n",
            "iter_dt 27.97ms; iter 10400: train loss 0.31250\n",
            "iter_dt 27.65ms; iter 10410: train loss 0.28412\n",
            "iter_dt 28.22ms; iter 10420: train loss 0.29401\n",
            "iter_dt 28.11ms; iter 10430: train loss 0.29991\n",
            "iter_dt 27.73ms; iter 10440: train loss 0.30063\n",
            "iter_dt 27.45ms; iter 10450: train loss 0.29625\n",
            "iter_dt 27.52ms; iter 10460: train loss 0.28882\n",
            "iter_dt 27.83ms; iter 10470: train loss 0.29583\n",
            "iter_dt 27.73ms; iter 10480: train loss 0.29070\n",
            "iter_dt 27.27ms; iter 10490: train loss 0.28522\n",
            "iter_dt 27.51ms; iter 10500: train loss 0.27431\n",
            "O God, O God! Véén, maar de sin van ééne kraant van de\n",
            "beenen in de winterze stampen voor 't las. Natuurlijk had ze Japi een\n",
            "goed zichtje, een gouden herfstdag, die niet zou eindigen. En hij\n",
            "streek een herfstdraad van z'n vader loopen, dien 't ook altijd goed was\n",
            "gegaan en die ook nooit iets bijzonders had bereikt. Hij zag zichzelf\n",
            "al loopen over 28 jaar, met net zoo'n hoofd en kreeg 't gevoel of i\n",
            "z'n eigen vader was. En drieentwintig jaar achter 'm liep z'n dochter,\n",
            "nu nog z'n dochter, die 't druk hebben e\n",
            "saving model\n",
            "iter_dt 30.53ms; iter 10510: train loss 0.28468\n",
            "iter_dt 27.86ms; iter 10520: train loss 0.29259\n",
            "iter_dt 27.40ms; iter 10530: train loss 0.30289\n",
            "iter_dt 31.52ms; iter 10540: train loss 0.28707\n",
            "iter_dt 31.64ms; iter 10550: train loss 0.29606\n",
            "iter_dt 27.51ms; iter 10560: train loss 0.28798\n",
            "iter_dt 27.38ms; iter 10570: train loss 0.29288\n",
            "iter_dt 27.57ms; iter 10580: train loss 0.29642\n",
            "iter_dt 27.36ms; iter 10590: train loss 0.29289\n",
            "iter_dt 27.10ms; iter 10600: train loss 0.31046\n",
            "iter_dt 27.15ms; iter 10610: train loss 0.27743\n",
            "iter_dt 27.21ms; iter 10620: train loss 0.28172\n",
            "iter_dt 27.33ms; iter 10630: train loss 0.28272\n",
            "iter_dt 27.43ms; iter 10640: train loss 0.29691\n",
            "iter_dt 26.96ms; iter 10650: train loss 0.28792\n",
            "iter_dt 27.05ms; iter 10660: train loss 0.28870\n",
            "iter_dt 27.72ms; iter 10670: train loss 0.29351\n",
            "iter_dt 27.41ms; iter 10680: train loss 0.29598\n",
            "iter_dt 27.46ms; iter 10690: train loss 0.30070\n",
            "iter_dt 27.43ms; iter 10700: train loss 0.28275\n",
            "iter_dt 28.44ms; iter 10710: train loss 0.29201\n",
            "iter_dt 27.45ms; iter 10720: train loss 0.28802\n",
            "iter_dt 27.41ms; iter 10730: train loss 0.29396\n",
            "iter_dt 27.43ms; iter 10740: train loss 0.29689\n",
            "iter_dt 27.75ms; iter 10750: train loss 0.28465\n",
            "iter_dt 28.26ms; iter 10760: train loss 0.28157\n",
            "iter_dt 27.64ms; iter 10770: train loss 0.28209\n",
            "iter_dt 28.54ms; iter 10780: train loss 0.27873\n",
            "iter_dt 28.15ms; iter 10790: train loss 0.29697\n",
            "iter_dt 28.23ms; iter 10800: train loss 0.27436\n",
            "iter_dt 28.26ms; iter 10810: train loss 0.27795\n",
            "iter_dt 27.50ms; iter 10820: train loss 0.29977\n",
            "iter_dt 27.61ms; iter 10830: train loss 0.28323\n",
            "iter_dt 27.32ms; iter 10840: train loss 0.28994\n",
            "iter_dt 27.68ms; iter 10850: train loss 0.27492\n",
            "iter_dt 28.77ms; iter 10860: train loss 0.26864\n",
            "iter_dt 28.27ms; iter 10870: train loss 0.29509\n",
            "iter_dt 28.20ms; iter 10880: train loss 0.29362\n",
            "iter_dt 28.05ms; iter 10890: train loss 0.27653\n",
            "iter_dt 28.16ms; iter 10900: train loss 0.29033\n",
            "iter_dt 28.31ms; iter 10910: train loss 0.29652\n",
            "iter_dt 28.50ms; iter 10920: train loss 0.28122\n",
            "iter_dt 29.12ms; iter 10930: train loss 0.28549\n",
            "iter_dt 28.01ms; iter 10940: train loss 0.29346\n",
            "iter_dt 27.99ms; iter 10950: train loss 0.27377\n",
            "iter_dt 27.43ms; iter 10960: train loss 0.28634\n",
            "iter_dt 27.94ms; iter 10970: train loss 0.27445\n",
            "iter_dt 28.64ms; iter 10980: train loss 0.29091\n",
            "iter_dt 28.23ms; iter 10990: train loss 0.28024\n",
            "iter_dt 28.50ms; iter 11000: train loss 0.28466\n",
            "O God, O God! Is Amsterdam en Bekker scheever gedronken.\" Meteen dragen ze, Goddank,\n",
            "dat de palen was bij haar sloeg op den rand van 't bed tusschen\n",
            "zijn knieën door naar 't kleed te staren. Hij stopte achter z'n stoel even groote hoed,\n",
            "z'n schoenen nog aan. \"Hallo\", riep ik en wees naar den modder te praten. Daarok wel liep: \"zou ik zijn, Goddank,\n",
            "dat ik een sentimen water spatten voor de paper op en raas van binnen\n",
            "donkerrood; dat brok steen was er nog maar wat van de tijden, die moest geen\n",
            "antwoord. Hij w\n",
            "saving model\n",
            "iter_dt 27.39ms; iter 11010: train loss 0.28264\n",
            "iter_dt 27.86ms; iter 11020: train loss 0.28180\n",
            "iter_dt 27.28ms; iter 11030: train loss 0.28064\n",
            "iter_dt 27.57ms; iter 11040: train loss 0.29237\n",
            "iter_dt 27.26ms; iter 11050: train loss 0.28148\n",
            "iter_dt 27.36ms; iter 11060: train loss 0.29157\n",
            "iter_dt 27.80ms; iter 11070: train loss 0.27527\n",
            "iter_dt 27.43ms; iter 11080: train loss 0.27900\n",
            "iter_dt 27.43ms; iter 11090: train loss 0.27610\n",
            "iter_dt 27.71ms; iter 11100: train loss 0.27589\n",
            "iter_dt 27.54ms; iter 11110: train loss 0.28436\n",
            "iter_dt 29.38ms; iter 11120: train loss 0.28159\n",
            "iter_dt 27.35ms; iter 11130: train loss 0.26811\n",
            "iter_dt 27.34ms; iter 11140: train loss 0.26907\n",
            "iter_dt 27.61ms; iter 11150: train loss 0.28076\n",
            "iter_dt 27.31ms; iter 11160: train loss 0.27029\n",
            "iter_dt 27.16ms; iter 11170: train loss 0.28834\n",
            "iter_dt 29.10ms; iter 11180: train loss 0.27909\n",
            "iter_dt 29.78ms; iter 11190: train loss 0.26867\n",
            "iter_dt 27.25ms; iter 11200: train loss 0.28354\n",
            "iter_dt 29.96ms; iter 11210: train loss 0.29284\n",
            "iter_dt 27.24ms; iter 11220: train loss 0.28924\n",
            "iter_dt 29.52ms; iter 11230: train loss 0.26989\n",
            "iter_dt 27.29ms; iter 11240: train loss 0.29740\n",
            "iter_dt 27.14ms; iter 11250: train loss 0.28135\n",
            "iter_dt 27.18ms; iter 11260: train loss 0.27518\n",
            "iter_dt 27.33ms; iter 11270: train loss 0.26768\n",
            "iter_dt 29.38ms; iter 11280: train loss 0.28092\n",
            "iter_dt 29.16ms; iter 11290: train loss 0.28924\n",
            "iter_dt 28.06ms; iter 11300: train loss 0.27746\n",
            "iter_dt 27.43ms; iter 11310: train loss 0.26834\n",
            "iter_dt 27.86ms; iter 11320: train loss 0.27301\n",
            "iter_dt 27.38ms; iter 11330: train loss 0.28227\n",
            "iter_dt 27.67ms; iter 11340: train loss 0.28535\n",
            "iter_dt 27.97ms; iter 11350: train loss 0.28873\n",
            "iter_dt 27.27ms; iter 11360: train loss 0.27174\n",
            "iter_dt 27.33ms; iter 11370: train loss 0.29367\n",
            "iter_dt 27.34ms; iter 11380: train loss 0.28553\n",
            "iter_dt 27.28ms; iter 11390: train loss 0.27600\n",
            "iter_dt 27.45ms; iter 11400: train loss 0.26609\n",
            "iter_dt 27.74ms; iter 11410: train loss 0.26819\n",
            "iter_dt 27.65ms; iter 11420: train loss 0.27980\n",
            "iter_dt 27.14ms; iter 11430: train loss 0.26566\n",
            "iter_dt 27.85ms; iter 11440: train loss 0.27754\n",
            "iter_dt 27.26ms; iter 11450: train loss 0.27450\n",
            "iter_dt 28.10ms; iter 11460: train loss 0.27298\n",
            "iter_dt 27.80ms; iter 11470: train loss 0.28489\n",
            "iter_dt 27.21ms; iter 11480: train loss 0.27028\n",
            "iter_dt 27.86ms; iter 11490: train loss 0.28874\n",
            "iter_dt 28.96ms; iter 11500: train loss 0.26486\n",
            "O God, O God! Natuur\", onder ze was dan ze\n",
            "nog er maakte iets anders dan een jaar of wat kibbelen ze 's morgens bij die ééne kraan\n",
            "en dan in Brussel. Mee prende wat ze op straat vijf. en ze voelde haar borsten\n",
            "groot werden. En 't gaan van de bladen, de bladerlooze kruinen en de armoedige drassige\n",
            "weilanden in den winter, al die dingen die ik zoo vaak gezien had\n",
            "en waaraan ik zoo vaak had gedacht in mijn afwezigheid en die ik zoo\n",
            "vaak weer zou zien en dat ik ben geen denken God van Nederland dan\n",
            "heeft ik gelo\n",
            "saving model\n",
            "iter_dt 27.66ms; iter 11510: train loss 0.27454\n",
            "iter_dt 27.16ms; iter 11520: train loss 0.28213\n",
            "iter_dt 28.52ms; iter 11530: train loss 0.27002\n",
            "iter_dt 27.19ms; iter 11540: train loss 0.27935\n",
            "iter_dt 27.83ms; iter 11550: train loss 0.28483\n",
            "iter_dt 27.48ms; iter 11560: train loss 0.26882\n",
            "iter_dt 27.77ms; iter 11570: train loss 0.28239\n",
            "iter_dt 27.53ms; iter 11580: train loss 0.27384\n",
            "iter_dt 28.08ms; iter 11590: train loss 0.26314\n",
            "iter_dt 27.65ms; iter 11600: train loss 0.29765\n",
            "iter_dt 27.34ms; iter 11610: train loss 0.26531\n",
            "iter_dt 27.26ms; iter 11620: train loss 0.27831\n",
            "iter_dt 27.94ms; iter 11630: train loss 0.27639\n",
            "iter_dt 27.40ms; iter 11640: train loss 0.27041\n",
            "iter_dt 27.64ms; iter 11650: train loss 0.28375\n",
            "iter_dt 27.45ms; iter 11660: train loss 0.27946\n",
            "iter_dt 27.58ms; iter 11670: train loss 0.26184\n",
            "iter_dt 28.61ms; iter 11680: train loss 0.26843\n",
            "iter_dt 27.56ms; iter 11690: train loss 0.26867\n",
            "iter_dt 27.29ms; iter 11700: train loss 0.28160\n",
            "iter_dt 27.36ms; iter 11710: train loss 0.27892\n",
            "iter_dt 27.42ms; iter 11720: train loss 0.27770\n",
            "iter_dt 27.21ms; iter 11730: train loss 0.28901\n",
            "iter_dt 27.37ms; iter 11740: train loss 0.27163\n",
            "iter_dt 27.42ms; iter 11750: train loss 0.25758\n",
            "iter_dt 27.47ms; iter 11760: train loss 0.26559\n",
            "iter_dt 27.51ms; iter 11770: train loss 0.26884\n",
            "iter_dt 27.78ms; iter 11780: train loss 0.26614\n",
            "iter_dt 27.68ms; iter 11790: train loss 0.27113\n",
            "iter_dt 28.01ms; iter 11800: train loss 0.26480\n",
            "iter_dt 27.27ms; iter 11810: train loss 0.27037\n",
            "iter_dt 27.76ms; iter 11820: train loss 0.28339\n",
            "iter_dt 27.58ms; iter 11830: train loss 0.26439\n",
            "iter_dt 27.66ms; iter 11840: train loss 0.26911\n",
            "iter_dt 27.87ms; iter 11850: train loss 0.27976\n",
            "iter_dt 27.91ms; iter 11860: train loss 0.27159\n",
            "iter_dt 27.84ms; iter 11870: train loss 0.27051\n",
            "iter_dt 28.01ms; iter 11880: train loss 0.24453\n",
            "iter_dt 27.89ms; iter 11890: train loss 0.27734\n",
            "iter_dt 28.10ms; iter 11900: train loss 0.25928\n",
            "iter_dt 28.30ms; iter 11910: train loss 0.25130\n",
            "iter_dt 28.99ms; iter 11920: train loss 0.27535\n",
            "iter_dt 27.82ms; iter 11930: train loss 0.26971\n",
            "iter_dt 28.17ms; iter 11940: train loss 0.27705\n",
            "iter_dt 27.74ms; iter 11950: train loss 0.26499\n",
            "iter_dt 29.04ms; iter 11960: train loss 0.27571\n",
            "iter_dt 29.80ms; iter 11970: train loss 0.25830\n",
            "iter_dt 27.35ms; iter 11980: train loss 0.27332\n",
            "iter_dt 29.40ms; iter 11990: train loss 0.27294\n",
            "iter_dt 27.87ms; iter 12000: train loss 0.26897\n",
            "O God, O God! Neen,\n",
            "van meneer?\" Hij sloot 't geval was.\n",
            "\n",
            "\"God, dat ze in Rhen God weet begon wat-i te komen in de haard, de\n",
            "Loei toen van een reis en een dag geen vol melke zon er van\n",
            "worden. Maar na een paar dagen zagen ze heel sampig bij en bovenlijft een stoel die vrij was;\n",
            "\"neem dat kistje geven heb.\" Ik had twee handel in 't bij mijn tafel\n",
            "bij afwachter op, zonder dat je er één begon die gedijnen met z'n\n",
            "drieën hadden ze 't een heel eind soldaat gemaakt en toen had Japi\n",
            "dikke boterhammen gesneden van B\n",
            "saving model\n",
            "iter_dt 29.14ms; iter 12010: train loss 0.26051\n",
            "iter_dt 27.73ms; iter 12020: train loss 0.26173\n",
            "iter_dt 29.16ms; iter 12030: train loss 0.25986\n",
            "iter_dt 27.15ms; iter 12040: train loss 0.26249\n",
            "iter_dt 29.20ms; iter 12050: train loss 0.25423\n",
            "iter_dt 27.20ms; iter 12060: train loss 0.25790\n",
            "iter_dt 27.08ms; iter 12070: train loss 0.25968\n",
            "iter_dt 27.74ms; iter 12080: train loss 0.26681\n",
            "iter_dt 27.12ms; iter 12090: train loss 0.27439\n",
            "iter_dt 27.57ms; iter 12100: train loss 0.27316\n",
            "iter_dt 27.66ms; iter 12110: train loss 0.26991\n",
            "iter_dt 27.16ms; iter 12120: train loss 0.27621\n",
            "iter_dt 27.31ms; iter 12130: train loss 0.26620\n",
            "iter_dt 27.19ms; iter 12140: train loss 0.27371\n",
            "iter_dt 27.01ms; iter 12150: train loss 0.25353\n",
            "iter_dt 27.22ms; iter 12160: train loss 0.27663\n",
            "iter_dt 27.24ms; iter 12170: train loss 0.26738\n",
            "iter_dt 27.03ms; iter 12180: train loss 0.25791\n",
            "iter_dt 27.79ms; iter 12190: train loss 0.25536\n",
            "iter_dt 27.17ms; iter 12200: train loss 0.27326\n",
            "iter_dt 27.21ms; iter 12210: train loss 0.28338\n",
            "iter_dt 27.25ms; iter 12220: train loss 0.27251\n",
            "iter_dt 27.21ms; iter 12230: train loss 0.26215\n",
            "iter_dt 27.27ms; iter 12240: train loss 0.26154\n",
            "iter_dt 27.32ms; iter 12250: train loss 0.26135\n",
            "iter_dt 26.97ms; iter 12260: train loss 0.26931\n",
            "iter_dt 27.34ms; iter 12270: train loss 0.26994\n",
            "iter_dt 28.26ms; iter 12280: train loss 0.25848\n",
            "iter_dt 27.37ms; iter 12290: train loss 0.27081\n",
            "iter_dt 28.38ms; iter 12300: train loss 0.27191\n",
            "iter_dt 27.15ms; iter 12310: train loss 0.27086\n",
            "iter_dt 27.30ms; iter 12320: train loss 0.27052\n",
            "iter_dt 27.52ms; iter 12330: train loss 0.26147\n",
            "iter_dt 27.26ms; iter 12340: train loss 0.27446\n",
            "iter_dt 27.54ms; iter 12350: train loss 0.27227\n",
            "iter_dt 28.10ms; iter 12360: train loss 0.26843\n",
            "iter_dt 27.47ms; iter 12370: train loss 0.26781\n",
            "iter_dt 27.61ms; iter 12380: train loss 0.26486\n",
            "iter_dt 27.44ms; iter 12390: train loss 0.25848\n",
            "iter_dt 27.27ms; iter 12400: train loss 0.27105\n",
            "iter_dt 27.22ms; iter 12410: train loss 0.26366\n",
            "iter_dt 27.33ms; iter 12420: train loss 0.27922\n",
            "iter_dt 27.41ms; iter 12430: train loss 0.26516\n",
            "iter_dt 27.33ms; iter 12440: train loss 0.26146\n",
            "iter_dt 27.52ms; iter 12450: train loss 0.26947\n",
            "iter_dt 27.39ms; iter 12460: train loss 0.26597\n",
            "iter_dt 27.80ms; iter 12470: train loss 0.26993\n",
            "iter_dt 28.42ms; iter 12480: train loss 0.25456\n",
            "iter_dt 27.71ms; iter 12490: train loss 0.26546\n",
            "iter_dt 27.34ms; iter 12500: train loss 0.27176\n",
            "O God, O God! Nederland heeft. Op mooie dagen wij\n",
            "niet betrekken van allen versleten. Met weer wat je er anders.\n",
            "\n",
            "Pa een dichtertje was nooit gevallen, zij maar rond op z'n bankje, hield z'n pet vast en\n",
            "liet zich nat worden. Het duurde nog al wat, voordat i\n",
            "nog weer zoo had gezegd: \"Daar heb je waarachtig diezelfde kerel.\" Hij\n",
            "stak zit met de tram, haar slag en zei: \"Dag Dora, als een daar stond in den roode\n",
            "pakte i met heel open. Ze keek in den haard rommelden waren toen ze zilverwit, met\n",
            "haar handen gepakt\n",
            "saving model\n",
            "iter_dt 28.00ms; iter 12510: train loss 0.24747\n",
            "iter_dt 27.06ms; iter 12520: train loss 0.25861\n",
            "iter_dt 27.26ms; iter 12530: train loss 0.26806\n",
            "iter_dt 27.16ms; iter 12540: train loss 0.26194\n",
            "iter_dt 27.09ms; iter 12550: train loss 0.27481\n",
            "iter_dt 27.17ms; iter 12560: train loss 0.26436\n",
            "iter_dt 27.15ms; iter 12570: train loss 0.25295\n",
            "iter_dt 27.17ms; iter 12580: train loss 0.25611\n",
            "iter_dt 27.29ms; iter 12590: train loss 0.26882\n",
            "iter_dt 27.39ms; iter 12600: train loss 0.26785\n",
            "iter_dt 27.27ms; iter 12610: train loss 0.25833\n",
            "iter_dt 27.18ms; iter 12620: train loss 0.27013\n",
            "iter_dt 27.17ms; iter 12630: train loss 0.25156\n",
            "iter_dt 27.46ms; iter 12640: train loss 0.25689\n",
            "iter_dt 29.72ms; iter 12650: train loss 0.26474\n",
            "iter_dt 27.57ms; iter 12660: train loss 0.25961\n",
            "iter_dt 27.31ms; iter 12670: train loss 0.26723\n",
            "iter_dt 27.21ms; iter 12680: train loss 0.26661\n",
            "iter_dt 27.18ms; iter 12690: train loss 0.25939\n",
            "iter_dt 27.21ms; iter 12700: train loss 0.25713\n",
            "iter_dt 27.64ms; iter 12710: train loss 0.26982\n",
            "iter_dt 27.09ms; iter 12720: train loss 0.26541\n",
            "iter_dt 27.43ms; iter 12730: train loss 0.25906\n",
            "iter_dt 29.02ms; iter 12740: train loss 0.26701\n",
            "iter_dt 27.32ms; iter 12750: train loss 0.25725\n",
            "iter_dt 27.15ms; iter 12760: train loss 0.25650\n",
            "iter_dt 27.64ms; iter 12770: train loss 0.26032\n",
            "iter_dt 27.30ms; iter 12780: train loss 0.26745\n",
            "iter_dt 27.29ms; iter 12790: train loss 0.26195\n",
            "iter_dt 27.22ms; iter 12800: train loss 0.26058\n",
            "iter_dt 27.46ms; iter 12810: train loss 0.26292\n",
            "iter_dt 27.36ms; iter 12820: train loss 0.26854\n",
            "iter_dt 27.26ms; iter 12830: train loss 0.26809\n",
            "iter_dt 27.57ms; iter 12840: train loss 0.28506\n",
            "iter_dt 27.53ms; iter 12850: train loss 0.26901\n",
            "iter_dt 27.47ms; iter 12860: train loss 0.26872\n",
            "iter_dt 27.50ms; iter 12870: train loss 0.26049\n",
            "iter_dt 27.16ms; iter 12880: train loss 0.26840\n",
            "iter_dt 27.64ms; iter 12890: train loss 0.25229\n",
            "iter_dt 27.31ms; iter 12900: train loss 0.24911\n",
            "iter_dt 27.38ms; iter 12910: train loss 0.26589\n",
            "iter_dt 27.86ms; iter 12920: train loss 0.26036\n",
            "iter_dt 29.30ms; iter 12930: train loss 0.25079\n",
            "iter_dt 28.15ms; iter 12940: train loss 0.24700\n",
            "iter_dt 29.10ms; iter 12950: train loss 0.26738\n",
            "iter_dt 27.25ms; iter 12960: train loss 0.25810\n",
            "iter_dt 29.75ms; iter 12970: train loss 0.24275\n",
            "iter_dt 27.34ms; iter 12980: train loss 0.26242\n",
            "iter_dt 29.27ms; iter 12990: train loss 0.26060\n",
            "iter_dt 27.20ms; iter 13000: train loss 0.26685\n",
            "O God, O God! En moe. En met een schrijft stilletjes zoo maar bewogen\n",
            "viel, vier uur hun lichten aan en conducteur was afgestond en toen zei i:\n",
            "\"ik geloof dat ik nat ben\", en lachte. Een kerel die smachtig sigaren van jaar op voor.\" \"Och, ieder z'n smaak gedaan\", zei Japi. \"Ik\n",
            "ook\", zei Bavink. \"U schildert niet?\" vroeg Bavink. Het was een\n",
            "rare burgermansvraag, maar Bavink dacht aan de levende en doode,\n",
            "duizende van de muur stond te denken, datti zulke mooie bewaagd was,\n",
            "voorbij de 's zondert gegaan bij hond\n",
            "saving model\n",
            "iter_dt 28.94ms; iter 13010: train loss 0.26692\n",
            "iter_dt 27.20ms; iter 13020: train loss 0.26270\n",
            "iter_dt 28.88ms; iter 13030: train loss 0.26292\n",
            "iter_dt 27.09ms; iter 13040: train loss 0.26739\n",
            "iter_dt 29.01ms; iter 13050: train loss 0.26130\n",
            "iter_dt 27.21ms; iter 13060: train loss 0.25455\n",
            "iter_dt 29.00ms; iter 13070: train loss 0.25662\n",
            "iter_dt 27.00ms; iter 13080: train loss 0.26344\n",
            "iter_dt 29.59ms; iter 13090: train loss 0.27591\n",
            "iter_dt 28.66ms; iter 13100: train loss 0.25926\n",
            "iter_dt 29.44ms; iter 13110: train loss 0.25076\n",
            "iter_dt 27.10ms; iter 13120: train loss 0.25317\n",
            "iter_dt 29.18ms; iter 13130: train loss 0.26398\n",
            "iter_dt 27.14ms; iter 13140: train loss 0.26194\n",
            "iter_dt 29.22ms; iter 13150: train loss 0.24776\n",
            "iter_dt 27.21ms; iter 13160: train loss 0.25696\n",
            "iter_dt 29.17ms; iter 13170: train loss 0.26685\n",
            "iter_dt 27.25ms; iter 13180: train loss 0.26399\n",
            "iter_dt 29.24ms; iter 13190: train loss 0.24291\n",
            "iter_dt 27.35ms; iter 13200: train loss 0.25261\n",
            "iter_dt 29.54ms; iter 13210: train loss 0.25527\n",
            "iter_dt 27.06ms; iter 13220: train loss 0.26227\n",
            "iter_dt 29.39ms; iter 13230: train loss 0.26245\n",
            "iter_dt 28.34ms; iter 13240: train loss 0.24565\n",
            "iter_dt 29.18ms; iter 13250: train loss 0.25011\n",
            "iter_dt 27.00ms; iter 13260: train loss 0.26200\n",
            "iter_dt 28.88ms; iter 13270: train loss 0.27428\n",
            "iter_dt 27.07ms; iter 13280: train loss 0.25529\n",
            "iter_dt 28.71ms; iter 13290: train loss 0.26515\n",
            "iter_dt 27.10ms; iter 13300: train loss 0.24625\n",
            "iter_dt 29.11ms; iter 13310: train loss 0.25003\n",
            "iter_dt 27.23ms; iter 13320: train loss 0.25676\n",
            "iter_dt 28.92ms; iter 13330: train loss 0.25637\n",
            "iter_dt 27.15ms; iter 13340: train loss 0.26774\n",
            "iter_dt 28.81ms; iter 13350: train loss 0.25719\n",
            "iter_dt 27.48ms; iter 13360: train loss 0.24331\n",
            "iter_dt 27.94ms; iter 13370: train loss 0.25967\n",
            "iter_dt 27.55ms; iter 13380: train loss 0.24846\n",
            "iter_dt 27.51ms; iter 13390: train loss 0.25317\n",
            "iter_dt 27.98ms; iter 13400: train loss 0.24931\n",
            "iter_dt 27.18ms; iter 13410: train loss 0.24499\n",
            "iter_dt 27.44ms; iter 13420: train loss 0.26972\n",
            "iter_dt 27.37ms; iter 13430: train loss 0.25735\n",
            "iter_dt 27.55ms; iter 13440: train loss 0.26887\n",
            "iter_dt 27.83ms; iter 13450: train loss 0.24793\n",
            "iter_dt 28.13ms; iter 13460: train loss 0.25196\n",
            "iter_dt 27.47ms; iter 13470: train loss 0.25207\n",
            "iter_dt 27.18ms; iter 13480: train loss 0.25245\n",
            "iter_dt 27.17ms; iter 13490: train loss 0.27109\n",
            "iter_dt 27.19ms; iter 13500: train loss 0.26267\n",
            "O God, O God! En maar heeft was maar getrouwd, die de bloemen pluien\n",
            "bezaden. Met twee dagen las niet al te best, en de thee, daartusschen niet meer\n",
            "kon. En daar ze een dichteresje was citeerde zich in de verte hoog, als een nieuwe tijd zou\n",
            "aanbreken. Bekker zou in den gang, voor zoo bleek gezien. Maar ik zat al\n",
            "dien tijd op de punt van een stoei, maar ik geloof niet, dat Hoyer\n",
            "daar iets van gesnapt heeft.\n",
            "\n",
            "Hoyer had kolossaal geboft. Ze hadden de ouwe stomme streek uitgehaald\n",
            "een naaktfiguur van hem te weig\n",
            "saving model\n",
            "iter_dt 28.25ms; iter 13510: train loss 0.25699\n",
            "iter_dt 27.06ms; iter 13520: train loss 0.24374\n",
            "iter_dt 27.80ms; iter 13530: train loss 0.24992\n",
            "iter_dt 27.21ms; iter 13540: train loss 0.25329\n",
            "iter_dt 27.50ms; iter 13550: train loss 0.26271\n",
            "iter_dt 27.28ms; iter 13560: train loss 0.26586\n",
            "iter_dt 27.38ms; iter 13570: train loss 0.25535\n",
            "iter_dt 27.27ms; iter 13580: train loss 0.25684\n",
            "iter_dt 27.14ms; iter 13590: train loss 0.24518\n",
            "iter_dt 27.24ms; iter 13600: train loss 0.25659\n",
            "iter_dt 27.38ms; iter 13610: train loss 0.25074\n",
            "iter_dt 27.30ms; iter 13620: train loss 0.24506\n",
            "iter_dt 27.06ms; iter 13630: train loss 0.26095\n",
            "iter_dt 27.60ms; iter 13640: train loss 0.24279\n",
            "iter_dt 27.40ms; iter 13650: train loss 0.25404\n",
            "iter_dt 27.16ms; iter 13660: train loss 0.26099\n",
            "iter_dt 27.27ms; iter 13670: train loss 0.25454\n",
            "iter_dt 27.31ms; iter 13680: train loss 0.26833\n",
            "iter_dt 27.38ms; iter 13690: train loss 0.25750\n",
            "iter_dt 27.11ms; iter 13700: train loss 0.26249\n",
            "iter_dt 27.42ms; iter 13710: train loss 0.25519\n",
            "iter_dt 28.44ms; iter 13720: train loss 0.25981\n",
            "iter_dt 27.24ms; iter 13730: train loss 0.26036\n",
            "iter_dt 27.40ms; iter 13740: train loss 0.25965\n",
            "iter_dt 27.30ms; iter 13750: train loss 0.25759\n",
            "iter_dt 27.26ms; iter 13760: train loss 0.26375\n",
            "iter_dt 27.13ms; iter 13770: train loss 0.25891\n",
            "iter_dt 27.22ms; iter 13780: train loss 0.25643\n",
            "iter_dt 27.27ms; iter 13790: train loss 0.25613\n",
            "iter_dt 27.33ms; iter 13800: train loss 0.24001\n",
            "iter_dt 27.15ms; iter 13810: train loss 0.26078\n",
            "iter_dt 27.42ms; iter 13820: train loss 0.25324\n",
            "iter_dt 27.54ms; iter 13830: train loss 0.24704\n",
            "iter_dt 27.50ms; iter 13840: train loss 0.26752\n",
            "iter_dt 27.45ms; iter 13850: train loss 0.24967\n",
            "iter_dt 27.40ms; iter 13860: train loss 0.24608\n",
            "iter_dt 27.63ms; iter 13870: train loss 0.27404\n",
            "iter_dt 27.76ms; iter 13880: train loss 0.25647\n",
            "iter_dt 27.59ms; iter 13890: train loss 0.24613\n",
            "iter_dt 27.49ms; iter 13900: train loss 0.24472\n",
            "iter_dt 27.14ms; iter 13910: train loss 0.25679\n",
            "iter_dt 29.47ms; iter 13920: train loss 0.24927\n",
            "iter_dt 27.94ms; iter 13930: train loss 0.24223\n",
            "iter_dt 27.17ms; iter 13940: train loss 0.24419\n",
            "iter_dt 27.26ms; iter 13950: train loss 0.24813\n",
            "iter_dt 27.22ms; iter 13960: train loss 0.24471\n",
            "iter_dt 27.05ms; iter 13970: train loss 0.24925\n",
            "iter_dt 27.17ms; iter 13980: train loss 0.24653\n",
            "iter_dt 27.87ms; iter 13990: train loss 0.24847\n",
            "iter_dt 28.09ms; iter 14000: train loss 0.25459\n",
            "O God, O God! En maar 't pa. Wat zou dat voor 'n vent zijn, die\n",
            "dat artikel geschreven heeft? Heb jij verantwoordelijkheidsgevoel. Ik kan me daar niet\n",
            "op. Ik kan moest niet mogen uitzien. \"Nu wordt ik zie 't in waardig, zoo lief ze later er niet al te veel\n",
            "wij zen niet achter zien. Ze hadden enkele dagen baantje aan den vouwen donker gaan,\n",
            "dat ze diep kwam had en dan kwam lachten ze dit gelige en toen van z'n kraag.\n",
            "\n",
            "Wat duurde zoo hij verdomde leuk gekund en zoo moest mooi weinig. Bavink snorde overal rond,\n",
            "saving model\n",
            "iter_dt 30.77ms; iter 14010: train loss 0.24799\n",
            "iter_dt 27.91ms; iter 14020: train loss 0.26513\n",
            "iter_dt 29.57ms; iter 14030: train loss 0.24669\n",
            "iter_dt 27.93ms; iter 14040: train loss 0.24831\n",
            "iter_dt 27.71ms; iter 14050: train loss 0.26034\n",
            "iter_dt 27.26ms; iter 14060: train loss 0.25365\n",
            "iter_dt 28.80ms; iter 14070: train loss 0.26567\n",
            "iter_dt 28.65ms; iter 14080: train loss 0.26197\n",
            "iter_dt 27.31ms; iter 14090: train loss 0.25221\n",
            "iter_dt 27.14ms; iter 14100: train loss 0.25464\n",
            "iter_dt 27.25ms; iter 14110: train loss 0.24430\n",
            "iter_dt 27.28ms; iter 14120: train loss 0.25428\n",
            "iter_dt 27.19ms; iter 14130: train loss 0.25122\n",
            "iter_dt 27.00ms; iter 14140: train loss 0.24773\n",
            "iter_dt 27.53ms; iter 14150: train loss 0.25199\n",
            "iter_dt 27.47ms; iter 14160: train loss 0.25608\n",
            "iter_dt 27.23ms; iter 14170: train loss 0.25858\n",
            "iter_dt 27.29ms; iter 14180: train loss 0.23921\n",
            "iter_dt 27.09ms; iter 14190: train loss 0.24321\n",
            "iter_dt 27.14ms; iter 14200: train loss 0.25321\n",
            "iter_dt 27.27ms; iter 14210: train loss 0.24871\n",
            "iter_dt 27.01ms; iter 14220: train loss 0.25285\n",
            "iter_dt 27.34ms; iter 14230: train loss 0.24382\n",
            "iter_dt 27.13ms; iter 14240: train loss 0.25193\n",
            "iter_dt 27.80ms; iter 14250: train loss 0.25260\n",
            "iter_dt 27.14ms; iter 14260: train loss 0.25280\n",
            "iter_dt 27.07ms; iter 14270: train loss 0.24706\n",
            "iter_dt 27.11ms; iter 14280: train loss 0.24904\n",
            "iter_dt 27.06ms; iter 14290: train loss 0.24900\n",
            "iter_dt 27.00ms; iter 14300: train loss 0.24167\n",
            "iter_dt 27.10ms; iter 14310: train loss 0.25233\n",
            "iter_dt 27.10ms; iter 14320: train loss 0.25134\n",
            "iter_dt 27.23ms; iter 14330: train loss 0.23802\n",
            "iter_dt 27.12ms; iter 14340: train loss 0.24652\n",
            "iter_dt 27.14ms; iter 14350: train loss 0.24134\n",
            "iter_dt 27.40ms; iter 14360: train loss 0.23982\n",
            "iter_dt 27.05ms; iter 14370: train loss 0.25013\n",
            "iter_dt 27.18ms; iter 14380: train loss 0.24508\n",
            "iter_dt 29.17ms; iter 14390: train loss 0.24395\n",
            "iter_dt 27.32ms; iter 14400: train loss 0.25070\n",
            "iter_dt 27.21ms; iter 14410: train loss 0.25349\n",
            "iter_dt 27.31ms; iter 14420: train loss 0.24842\n",
            "iter_dt 27.37ms; iter 14430: train loss 0.24563\n",
            "iter_dt 27.34ms; iter 14440: train loss 0.25161\n",
            "iter_dt 27.15ms; iter 14450: train loss 0.25347\n",
            "iter_dt 27.34ms; iter 14460: train loss 0.24751\n",
            "iter_dt 29.68ms; iter 14470: train loss 0.24900\n",
            "iter_dt 27.37ms; iter 14480: train loss 0.25245\n",
            "iter_dt 29.31ms; iter 14490: train loss 0.25120\n",
            "iter_dt 27.34ms; iter 14500: train loss 0.25962\n",
            "O God, O God! Eduillemaal hebt.\"\n",
            "\n",
            "Ik zoet daar te slurpen. De deur trok. Vage visioenen had ik\n",
            "van de Cunera, van den hoek van den Grebbebebeberg met kantaaltje, aan den\n",
            "buitenkant tusschen pink en pols. Het is in 't begin van Mei. Voor 't\n",
            "eerst van 't jaar heeft ze een bloese aan die driehoekig is uitgesneden\n",
            "en ook haar borst is wit, zoo erg wit, dat de duivel moet denken aan\n",
            "het licht uit den hemel. En de hoeken van haar sleutelbeenderen bij 't\n",
            "kuin de haren af. En dan kwam i er een meisje met een viool i\n",
            "saving model\n",
            "iter_dt 29.94ms; iter 14510: train loss 0.25162\n",
            "iter_dt 27.38ms; iter 14520: train loss 0.25575\n",
            "iter_dt 27.24ms; iter 14530: train loss 0.23476\n",
            "iter_dt 27.39ms; iter 14540: train loss 0.25819\n",
            "iter_dt 27.39ms; iter 14550: train loss 0.24526\n",
            "iter_dt 27.72ms; iter 14560: train loss 0.25231\n",
            "iter_dt 27.11ms; iter 14570: train loss 0.24346\n",
            "iter_dt 27.64ms; iter 14580: train loss 0.24653\n",
            "iter_dt 26.95ms; iter 14590: train loss 0.23997\n",
            "iter_dt 27.22ms; iter 14600: train loss 0.26672\n",
            "iter_dt 27.02ms; iter 14610: train loss 0.25363\n",
            "iter_dt 27.63ms; iter 14620: train loss 0.25661\n",
            "iter_dt 27.04ms; iter 14630: train loss 0.24353\n",
            "iter_dt 27.44ms; iter 14640: train loss 0.25328\n",
            "iter_dt 27.52ms; iter 14650: train loss 0.24873\n",
            "iter_dt 27.07ms; iter 14660: train loss 0.23524\n",
            "iter_dt 27.00ms; iter 14670: train loss 0.25575\n",
            "iter_dt 27.38ms; iter 14680: train loss 0.25857\n",
            "iter_dt 27.37ms; iter 14690: train loss 0.25491\n",
            "iter_dt 27.49ms; iter 14700: train loss 0.24424\n",
            "iter_dt 28.05ms; iter 14710: train loss 0.24265\n",
            "iter_dt 28.00ms; iter 14720: train loss 0.24657\n",
            "iter_dt 27.13ms; iter 14730: train loss 0.25197\n",
            "iter_dt 27.58ms; iter 14740: train loss 0.25884\n",
            "iter_dt 27.76ms; iter 14750: train loss 0.25766\n",
            "iter_dt 27.09ms; iter 14760: train loss 0.24790\n",
            "iter_dt 27.23ms; iter 14770: train loss 0.25169\n",
            "iter_dt 27.07ms; iter 14780: train loss 0.23801\n",
            "iter_dt 27.11ms; iter 14790: train loss 0.24211\n",
            "iter_dt 27.17ms; iter 14800: train loss 0.25858\n",
            "iter_dt 27.24ms; iter 14810: train loss 0.25361\n",
            "iter_dt 27.12ms; iter 14820: train loss 0.24226\n",
            "iter_dt 27.67ms; iter 14830: train loss 0.25598\n",
            "iter_dt 27.12ms; iter 14840: train loss 0.23551\n",
            "iter_dt 27.18ms; iter 14850: train loss 0.24453\n",
            "iter_dt 28.12ms; iter 14860: train loss 0.25550\n",
            "iter_dt 27.83ms; iter 14870: train loss 0.24976\n",
            "iter_dt 27.14ms; iter 14880: train loss 0.23469\n",
            "iter_dt 28.03ms; iter 14890: train loss 0.24629\n",
            "iter_dt 27.22ms; iter 14900: train loss 0.23367\n",
            "iter_dt 27.49ms; iter 14910: train loss 0.24776\n",
            "iter_dt 27.29ms; iter 14920: train loss 0.24502\n",
            "iter_dt 27.73ms; iter 14930: train loss 0.24772\n",
            "iter_dt 27.31ms; iter 14940: train loss 0.25980\n",
            "iter_dt 28.62ms; iter 14950: train loss 0.24176\n",
            "iter_dt 27.74ms; iter 14960: train loss 0.23871\n",
            "iter_dt 28.11ms; iter 14970: train loss 0.25259\n",
            "iter_dt 27.28ms; iter 14980: train loss 0.24453\n",
            "iter_dt 27.21ms; iter 14990: train loss 0.24645\n",
            "iter_dt 27.74ms; iter 15000: train loss 0.24486\n",
            "O God, O God! Alleen heen en de dag,\n",
            "al leeren. Neem hemel had hij met z'n rechterhand, z'n rechterarm\n",
            "steunde op de verschansing. 't Woei zoo hard, dat Bavink z'n hand\n",
            "opzij van z'n neus moest houden om adem te halen. Japi zat daar maar,\n",
            "alsof hij thuis was. Toen vertelde Japi dat i van plan was, nog enkele\n",
            "weken in Veere te zitten, tot zijn geld op was.\n",
            "\n",
            "Schilderen leek 'm wel aardig, als je 't goed kon. Hij kon niks, en\n",
            "daarom deed i maar niks. Je kon toch de dingen niet zoo weergeven als\n",
            "je ze onderging.\n",
            "saving model\n",
            "iter_dt 27.75ms; iter 15010: train loss 0.24267\n",
            "iter_dt 27.31ms; iter 15020: train loss 0.24926\n",
            "iter_dt 27.63ms; iter 15030: train loss 0.23784\n",
            "iter_dt 27.23ms; iter 15040: train loss 0.25016\n",
            "iter_dt 27.56ms; iter 15050: train loss 0.25164\n",
            "iter_dt 27.88ms; iter 15060: train loss 0.24783\n",
            "iter_dt 27.55ms; iter 15070: train loss 0.23901\n",
            "iter_dt 27.40ms; iter 15080: train loss 0.25059\n",
            "iter_dt 27.25ms; iter 15090: train loss 0.24281\n",
            "iter_dt 27.14ms; iter 15100: train loss 0.24391\n",
            "iter_dt 27.31ms; iter 15110: train loss 0.25062\n",
            "iter_dt 27.20ms; iter 15120: train loss 0.24455\n",
            "iter_dt 27.33ms; iter 15130: train loss 0.24564\n",
            "iter_dt 27.14ms; iter 15140: train loss 0.24738\n",
            "iter_dt 27.16ms; iter 15150: train loss 0.23913\n",
            "iter_dt 27.08ms; iter 15160: train loss 0.23466\n",
            "iter_dt 27.26ms; iter 15170: train loss 0.25920\n",
            "iter_dt 27.06ms; iter 15180: train loss 0.24757\n",
            "iter_dt 27.29ms; iter 15190: train loss 0.23659\n",
            "iter_dt 27.13ms; iter 15200: train loss 0.25908\n",
            "iter_dt 27.25ms; iter 15210: train loss 0.24094\n",
            "iter_dt 27.16ms; iter 15220: train loss 0.23807\n",
            "iter_dt 27.52ms; iter 15230: train loss 0.24118\n",
            "iter_dt 27.60ms; iter 15240: train loss 0.24826\n",
            "iter_dt 27.42ms; iter 15250: train loss 0.25470\n",
            "iter_dt 27.20ms; iter 15260: train loss 0.24095\n",
            "iter_dt 28.03ms; iter 15270: train loss 0.24403\n",
            "iter_dt 27.37ms; iter 15280: train loss 0.24731\n",
            "iter_dt 27.76ms; iter 15290: train loss 0.22844\n",
            "iter_dt 27.16ms; iter 15300: train loss 0.24690\n",
            "iter_dt 28.03ms; iter 15310: train loss 0.25276\n",
            "iter_dt 27.57ms; iter 15320: train loss 0.23921\n",
            "iter_dt 27.80ms; iter 15330: train loss 0.24214\n",
            "iter_dt 27.23ms; iter 15340: train loss 0.23535\n",
            "iter_dt 27.41ms; iter 15350: train loss 0.24480\n",
            "iter_dt 27.29ms; iter 15360: train loss 0.24479\n",
            "iter_dt 27.28ms; iter 15370: train loss 0.24276\n",
            "iter_dt 27.57ms; iter 15380: train loss 0.25163\n",
            "iter_dt 27.26ms; iter 15390: train loss 0.22430\n",
            "iter_dt 27.53ms; iter 15400: train loss 0.24460\n",
            "iter_dt 27.19ms; iter 15410: train loss 0.23818\n",
            "iter_dt 27.16ms; iter 15420: train loss 0.24521\n",
            "iter_dt 29.25ms; iter 15430: train loss 0.24245\n",
            "iter_dt 27.23ms; iter 15440: train loss 0.23650\n",
            "iter_dt 27.70ms; iter 15450: train loss 0.24896\n",
            "iter_dt 27.18ms; iter 15460: train loss 0.25928\n",
            "iter_dt 27.40ms; iter 15470: train loss 0.24175\n",
            "iter_dt 27.51ms; iter 15480: train loss 0.25008\n",
            "iter_dt 27.25ms; iter 15490: train loss 0.24717\n",
            "iter_dt 27.43ms; iter 15500: train loss 0.23958\n",
            "O God, O God!7 mensche me schel zoo over boven huis bij de puilten? In een net verden. Ik keek\n",
            "er naar niet bij over. De zon van die monu stilletjes en geen oogenblik gelijk. En\n",
            "daarna had je dikke Jan ook weer, den toren van Zierikzee, nu in 't\n",
            "kleine kuisje in\n",
            "'t water te razen. Daarnaast stond m'n troost bestaan. De treurwilg zij in een volksbuurt, waar weer zeiden in 't\n",
            "alsterdampje en geen oogenblik 't zelfde. Eenen keer hield ze diep\n",
            "ze niet verlegenheid zooals als i kleinste vasthiel en verlangen over\n",
            "saving model\n",
            "iter_dt 27.17ms; iter 15510: train loss 0.22735\n",
            "iter_dt 27.15ms; iter 15520: train loss 0.24843\n",
            "iter_dt 27.63ms; iter 15530: train loss 0.23261\n",
            "iter_dt 27.68ms; iter 15540: train loss 0.23858\n",
            "iter_dt 27.29ms; iter 15550: train loss 0.23856\n",
            "iter_dt 27.49ms; iter 15560: train loss 0.24002\n",
            "iter_dt 27.22ms; iter 15570: train loss 0.25109\n",
            "iter_dt 27.37ms; iter 15580: train loss 0.23285\n",
            "iter_dt 27.55ms; iter 15590: train loss 0.25088\n",
            "iter_dt 27.31ms; iter 15600: train loss 0.24520\n",
            "iter_dt 28.09ms; iter 15610: train loss 0.24924\n",
            "iter_dt 29.32ms; iter 15620: train loss 0.23989\n",
            "iter_dt 27.20ms; iter 15630: train loss 0.25540\n",
            "iter_dt 27.60ms; iter 15640: train loss 0.23759\n",
            "iter_dt 27.23ms; iter 15650: train loss 0.24216\n",
            "iter_dt 27.15ms; iter 15660: train loss 0.24890\n",
            "iter_dt 27.37ms; iter 15670: train loss 0.24485\n",
            "iter_dt 27.35ms; iter 15680: train loss 0.24285\n",
            "iter_dt 27.30ms; iter 15690: train loss 0.23887\n",
            "iter_dt 27.14ms; iter 15700: train loss 0.23545\n",
            "iter_dt 27.95ms; iter 15710: train loss 0.24460\n",
            "iter_dt 27.52ms; iter 15720: train loss 0.23563\n",
            "iter_dt 29.24ms; iter 15730: train loss 0.23790\n",
            "iter_dt 27.38ms; iter 15740: train loss 0.24549\n",
            "iter_dt 27.64ms; iter 15750: train loss 0.23248\n",
            "iter_dt 27.52ms; iter 15760: train loss 0.24836\n",
            "iter_dt 27.07ms; iter 15770: train loss 0.23071\n",
            "iter_dt 27.34ms; iter 15780: train loss 0.26292\n",
            "iter_dt 27.21ms; iter 15790: train loss 0.24308\n",
            "iter_dt 27.23ms; iter 15800: train loss 0.23995\n",
            "iter_dt 26.97ms; iter 15810: train loss 0.24654\n",
            "iter_dt 27.18ms; iter 15820: train loss 0.24495\n",
            "iter_dt 27.10ms; iter 15830: train loss 0.23787\n",
            "iter_dt 27.05ms; iter 15840: train loss 0.25072\n",
            "iter_dt 27.07ms; iter 15850: train loss 0.23742\n",
            "iter_dt 27.26ms; iter 15860: train loss 0.23882\n",
            "iter_dt 27.93ms; iter 15870: train loss 0.23787\n",
            "iter_dt 27.09ms; iter 15880: train loss 0.24611\n",
            "iter_dt 27.15ms; iter 15890: train loss 0.22709\n",
            "iter_dt 28.06ms; iter 15900: train loss 0.24894\n",
            "iter_dt 27.15ms; iter 15910: train loss 0.23795\n",
            "iter_dt 27.12ms; iter 15920: train loss 0.23306\n",
            "iter_dt 27.09ms; iter 15930: train loss 0.23550\n",
            "iter_dt 27.44ms; iter 15940: train loss 0.22976\n",
            "iter_dt 27.27ms; iter 15950: train loss 0.22471\n",
            "iter_dt 27.13ms; iter 15960: train loss 0.22537\n",
            "iter_dt 27.23ms; iter 15970: train loss 0.23565\n",
            "iter_dt 27.25ms; iter 15980: train loss 0.24592\n",
            "iter_dt 27.07ms; iter 15990: train loss 0.24151\n",
            "iter_dt 27.27ms; iter 16000: train loss 0.24062\n",
            "O God, O God! En\n",
            "maar hebben ze dan de Overtoom gedempt? 't Was geen gezicht om dien stijven kerel\n",
            "er over te zien springen, dat wilden ze niet meer hebben. Die f 300\n",
            "à 400 bevallen me wel, de rest trekt me minder aan\"\n",
            "\n",
            "\"Wilt u daarop schrijven?\" vroeg ik--\"Jij, als 't ublieft,\" zei\n",
            "Japi. \"Willen? Ik moet van de ouwe heer. Hij zegt: 't kan zoo\n",
            "niet blijven doorgaan. Ik zie niet in, wat niet. Heeft hij last\n",
            "van me? In vijf weken hebben we daar? 't Is hier een beetje donker. Zoo,\n",
            "en in 't versche Koekebakker, \n",
            "saving model\n",
            "iter_dt 27.30ms; iter 16010: train loss 0.24675\n",
            "iter_dt 27.41ms; iter 16020: train loss 0.23822\n",
            "iter_dt 28.71ms; iter 16030: train loss 0.23758\n",
            "iter_dt 27.45ms; iter 16040: train loss 0.24340\n",
            "iter_dt 27.29ms; iter 16050: train loss 0.24109\n",
            "iter_dt 27.34ms; iter 16060: train loss 0.24685\n",
            "iter_dt 27.30ms; iter 16070: train loss 0.23433\n",
            "iter_dt 27.71ms; iter 16080: train loss 0.23412\n",
            "iter_dt 27.62ms; iter 16090: train loss 0.24153\n",
            "iter_dt 27.52ms; iter 16100: train loss 0.23711\n",
            "iter_dt 27.45ms; iter 16110: train loss 0.24319\n",
            "iter_dt 27.25ms; iter 16120: train loss 0.23747\n",
            "iter_dt 27.85ms; iter 16130: train loss 0.24492\n",
            "iter_dt 27.19ms; iter 16140: train loss 0.24738\n",
            "iter_dt 27.32ms; iter 16150: train loss 0.22709\n",
            "iter_dt 29.63ms; iter 16160: train loss 0.23724\n",
            "iter_dt 27.23ms; iter 16170: train loss 0.23403\n",
            "iter_dt 29.13ms; iter 16180: train loss 0.24670\n",
            "iter_dt 27.84ms; iter 16190: train loss 0.23379\n",
            "iter_dt 29.05ms; iter 16200: train loss 0.23552\n",
            "iter_dt 27.64ms; iter 16210: train loss 0.23688\n",
            "iter_dt 28.85ms; iter 16220: train loss 0.23413\n",
            "iter_dt 27.16ms; iter 16230: train loss 0.24315\n",
            "iter_dt 28.89ms; iter 16240: train loss 0.23860\n",
            "iter_dt 27.02ms; iter 16250: train loss 0.24287\n",
            "iter_dt 29.06ms; iter 16260: train loss 0.23823\n",
            "iter_dt 27.20ms; iter 16270: train loss 0.24039\n",
            "iter_dt 28.99ms; iter 16280: train loss 0.23725\n",
            "iter_dt 26.98ms; iter 16290: train loss 0.23477\n",
            "iter_dt 28.93ms; iter 16300: train loss 0.23286\n",
            "iter_dt 27.07ms; iter 16310: train loss 0.24215\n",
            "iter_dt 28.96ms; iter 16320: train loss 0.22807\n",
            "iter_dt 27.16ms; iter 16330: train loss 0.24470\n",
            "iter_dt 29.01ms; iter 16340: train loss 0.23606\n",
            "iter_dt 27.05ms; iter 16350: train loss 0.22377\n",
            "iter_dt 27.16ms; iter 16360: train loss 0.25377\n",
            "iter_dt 27.06ms; iter 16370: train loss 0.22599\n",
            "iter_dt 27.12ms; iter 16380: train loss 0.24293\n",
            "iter_dt 27.10ms; iter 16390: train loss 0.23720\n",
            "iter_dt 27.11ms; iter 16400: train loss 0.23987\n",
            "iter_dt 27.41ms; iter 16410: train loss 0.24061\n",
            "iter_dt 27.20ms; iter 16420: train loss 0.23743\n",
            "iter_dt 27.32ms; iter 16430: train loss 0.22694\n",
            "iter_dt 27.13ms; iter 16440: train loss 0.23598\n",
            "iter_dt 27.26ms; iter 16450: train loss 0.24386\n",
            "iter_dt 27.16ms; iter 16460: train loss 0.23046\n",
            "iter_dt 27.97ms; iter 16470: train loss 0.23590\n",
            "iter_dt 27.85ms; iter 16480: train loss 0.23233\n",
            "iter_dt 27.51ms; iter 16490: train loss 0.22565\n",
            "iter_dt 27.39ms; iter 16500: train loss 0.25003\n",
            "O God, O God! Nederlandsche straat liep 't bestaan en lachten ze bijna\n",
            "in de sloot. Andere hoorde je zachtjes, ver, heel ver weg. Een koe,\n",
            "die je nauwelijks meer kon zien in de donkere kamer,\n",
            "en keek naar 't gele licht van de straatlantaarn op 't plafond en naar\n",
            "'t roode schijnsel van den haard op de vloer.\n",
            "\n",
            "Achter 't huis was de stad en 't lamplicht in vele vensters, maar\n",
            "dat zagen ze niet, want ze zaten voòr en als Dora opkeek zag ze 't\n",
            "land, waar 't laatste licht de hooge lucht verliet, over de aarde was\n",
            "\n",
            "saving model\n",
            "iter_dt 27.34ms; iter 16510: train loss 0.23678\n",
            "iter_dt 27.27ms; iter 16520: train loss 0.23735\n",
            "iter_dt 28.36ms; iter 16530: train loss 0.22625\n",
            "iter_dt 27.37ms; iter 16540: train loss 0.23551\n",
            "iter_dt 27.41ms; iter 16550: train loss 0.23158\n",
            "iter_dt 27.43ms; iter 16560: train loss 0.23930\n",
            "iter_dt 28.03ms; iter 16570: train loss 0.23647\n",
            "iter_dt 27.27ms; iter 16580: train loss 0.23106\n",
            "iter_dt 27.59ms; iter 16590: train loss 0.22562\n",
            "iter_dt 27.60ms; iter 16600: train loss 0.24365\n",
            "iter_dt 29.33ms; iter 16610: train loss 0.23194\n",
            "iter_dt 27.58ms; iter 16620: train loss 0.23542\n",
            "iter_dt 27.20ms; iter 16630: train loss 0.24187\n",
            "iter_dt 27.28ms; iter 16640: train loss 0.23272\n",
            "iter_dt 27.63ms; iter 16650: train loss 0.23377\n",
            "iter_dt 27.20ms; iter 16660: train loss 0.23142\n",
            "iter_dt 27.18ms; iter 16670: train loss 0.23527\n",
            "iter_dt 27.11ms; iter 16680: train loss 0.23069\n",
            "iter_dt 27.16ms; iter 16690: train loss 0.22559\n",
            "iter_dt 29.10ms; iter 16700: train loss 0.24600\n",
            "iter_dt 27.62ms; iter 16710: train loss 0.24559\n",
            "iter_dt 29.07ms; iter 16720: train loss 0.22355\n",
            "iter_dt 27.13ms; iter 16730: train loss 0.22217\n",
            "iter_dt 29.32ms; iter 16740: train loss 0.23509\n",
            "iter_dt 27.23ms; iter 16750: train loss 0.24443\n",
            "iter_dt 29.32ms; iter 16760: train loss 0.22951\n",
            "iter_dt 27.07ms; iter 16770: train loss 0.23986\n",
            "iter_dt 29.45ms; iter 16780: train loss 0.23307\n",
            "iter_dt 27.28ms; iter 16790: train loss 0.23062\n",
            "iter_dt 29.39ms; iter 16800: train loss 0.24044\n",
            "iter_dt 27.41ms; iter 16810: train loss 0.24149\n",
            "iter_dt 29.23ms; iter 16820: train loss 0.23401\n",
            "iter_dt 27.61ms; iter 16830: train loss 0.22460\n",
            "iter_dt 27.19ms; iter 16840: train loss 0.23670\n",
            "iter_dt 27.78ms; iter 16850: train loss 0.23728\n",
            "iter_dt 27.04ms; iter 16860: train loss 0.24235\n",
            "iter_dt 27.05ms; iter 16870: train loss 0.23682\n",
            "iter_dt 27.21ms; iter 16880: train loss 0.23931\n",
            "iter_dt 27.15ms; iter 16890: train loss 0.23723\n",
            "iter_dt 27.20ms; iter 16900: train loss 0.24551\n",
            "iter_dt 27.23ms; iter 16910: train loss 0.23001\n",
            "iter_dt 27.04ms; iter 16920: train loss 0.23413\n",
            "iter_dt 27.04ms; iter 16930: train loss 0.22591\n",
            "iter_dt 27.16ms; iter 16940: train loss 0.23117\n",
            "iter_dt 27.10ms; iter 16950: train loss 0.24329\n",
            "iter_dt 27.08ms; iter 16960: train loss 0.24031\n",
            "iter_dt 27.29ms; iter 16970: train loss 0.24007\n",
            "iter_dt 27.11ms; iter 16980: train loss 0.23316\n",
            "iter_dt 27.16ms; iter 16990: train loss 0.23464\n",
            "iter_dt 28.67ms; iter 17000: train loss 0.23185\n",
            "O God, O God! Ze heeft wel eens zoo'n woeste werker te worden?\n",
            "\n",
            "O nee. Te sappel had i zich gemaakt. Vijftien jaar ouder geworden\n",
            "was i in de laatste drie, vier jaar.\n",
            "\n",
            "Toen stak i een versche sigaar op, van mij, een sigaar van een\n",
            "dubbeltje, met een bandje, ik was toen in goeden doen. Het bandje\n",
            "deed i er af.\n",
            "\n",
            "Geploeterd hatti, misère gezien hatti. In Marchienne aux Ponts\n",
            "en Charleroi was het begonnen. Voorbij de kamerige licht van den haard warmoeden en de kleur open\n",
            "om te denken, dat de vond dat ze vrijwel\n",
            "saving model\n",
            "iter_dt 27.27ms; iter 17010: train loss 0.22896\n",
            "iter_dt 27.41ms; iter 17020: train loss 0.24103\n",
            "iter_dt 27.31ms; iter 17030: train loss 0.23087\n",
            "iter_dt 27.47ms; iter 17040: train loss 0.23302\n",
            "iter_dt 27.26ms; iter 17050: train loss 0.22672\n",
            "iter_dt 27.73ms; iter 17060: train loss 0.22801\n",
            "iter_dt 27.52ms; iter 17070: train loss 0.22685\n",
            "iter_dt 27.50ms; iter 17080: train loss 0.22782\n",
            "iter_dt 27.26ms; iter 17090: train loss 0.23254\n",
            "iter_dt 28.25ms; iter 17100: train loss 0.24033\n",
            "iter_dt 27.18ms; iter 17110: train loss 0.23720\n",
            "iter_dt 29.53ms; iter 17120: train loss 0.22907\n",
            "iter_dt 27.26ms; iter 17130: train loss 0.24633\n",
            "iter_dt 27.72ms; iter 17140: train loss 0.23259\n",
            "iter_dt 27.64ms; iter 17150: train loss 0.24505\n",
            "iter_dt 27.25ms; iter 17160: train loss 0.22639\n",
            "iter_dt 28.19ms; iter 17170: train loss 0.23069\n",
            "iter_dt 28.12ms; iter 17180: train loss 0.23094\n",
            "iter_dt 27.22ms; iter 17190: train loss 0.23717\n",
            "iter_dt 27.47ms; iter 17200: train loss 0.23980\n",
            "iter_dt 27.61ms; iter 17210: train loss 0.23430\n",
            "iter_dt 27.44ms; iter 17220: train loss 0.24358\n",
            "iter_dt 27.16ms; iter 17230: train loss 0.24400\n",
            "iter_dt 27.13ms; iter 17240: train loss 0.23054\n",
            "iter_dt 27.29ms; iter 17250: train loss 0.24034\n",
            "iter_dt 27.17ms; iter 17260: train loss 0.22371\n",
            "iter_dt 27.33ms; iter 17270: train loss 0.22794\n",
            "iter_dt 27.17ms; iter 17280: train loss 0.23561\n",
            "iter_dt 27.21ms; iter 17290: train loss 0.23125\n",
            "iter_dt 27.09ms; iter 17300: train loss 0.22967\n",
            "iter_dt 27.20ms; iter 17310: train loss 0.22304\n",
            "iter_dt 27.30ms; iter 17320: train loss 0.22319\n",
            "iter_dt 27.39ms; iter 17330: train loss 0.23350\n",
            "iter_dt 27.06ms; iter 17340: train loss 0.22309\n",
            "iter_dt 27.17ms; iter 17350: train loss 0.23787\n",
            "iter_dt 27.18ms; iter 17360: train loss 0.22973\n",
            "iter_dt 27.06ms; iter 17370: train loss 0.23740\n",
            "iter_dt 27.21ms; iter 17380: train loss 0.23903\n",
            "iter_dt 27.05ms; iter 17390: train loss 0.24270\n",
            "iter_dt 27.27ms; iter 17400: train loss 0.24694\n",
            "iter_dt 27.40ms; iter 17410: train loss 0.22430\n",
            "iter_dt 27.34ms; iter 17420: train loss 0.21751\n",
            "iter_dt 29.45ms; iter 17430: train loss 0.23972\n",
            "iter_dt 27.24ms; iter 17440: train loss 0.24056\n",
            "iter_dt 29.05ms; iter 17450: train loss 0.23085\n",
            "iter_dt 27.12ms; iter 17460: train loss 0.24295\n",
            "iter_dt 27.41ms; iter 17470: train loss 0.22609\n",
            "iter_dt 27.42ms; iter 17480: train loss 0.23382\n",
            "iter_dt 27.38ms; iter 17490: train loss 0.22472\n",
            "iter_dt 27.58ms; iter 17500: train loss 0.21873\n",
            "O God, O God! Neen, dan gele raakte i te maken\n",
            "kon.\" En als Bavink werkte dan zat Japi er bij in 't gras of binnen,\n",
            "omgekeerd op een stoel en rookte. En aan 't prakkizeeren raad en een paar bij de straat over. \"Je weet je wat er aan\n",
            "hebben? Wie halve kon zijn niet best van niet goed meer op. De aarde joeg voort in de\n",
            "deur lange schoonmoeder en die was allerliefst voor Coba.\n",
            "\n",
            "\"Wat heb je daar een snoezig taschje.\" \"Uit 't City-magazijn?\" \"Nee,\n",
            "van Liberty\".\n",
            "\n",
            "\"Dat was voor de Parenger op stond, van avond is 't\n",
            "saving model\n",
            "iter_dt 27.75ms; iter 17510: train loss 0.21444\n",
            "iter_dt 27.72ms; iter 17520: train loss 0.23311\n",
            "iter_dt 27.45ms; iter 17530: train loss 0.23167\n",
            "iter_dt 27.37ms; iter 17540: train loss 0.24052\n",
            "iter_dt 27.73ms; iter 17550: train loss 0.22193\n",
            "iter_dt 27.69ms; iter 17560: train loss 0.23007\n",
            "iter_dt 28.09ms; iter 17570: train loss 0.23017\n",
            "iter_dt 27.41ms; iter 17580: train loss 0.23466\n",
            "iter_dt 27.40ms; iter 17590: train loss 0.23402\n",
            "iter_dt 27.41ms; iter 17600: train loss 0.22058\n",
            "iter_dt 27.28ms; iter 17610: train loss 0.23202\n",
            "iter_dt 27.61ms; iter 17620: train loss 0.23035\n",
            "iter_dt 27.25ms; iter 17630: train loss 0.23665\n",
            "iter_dt 27.31ms; iter 17640: train loss 0.23328\n",
            "iter_dt 28.27ms; iter 17650: train loss 0.23274\n",
            "iter_dt 27.20ms; iter 17660: train loss 0.22494\n",
            "iter_dt 27.30ms; iter 17670: train loss 0.22363\n",
            "iter_dt 28.09ms; iter 17680: train loss 0.22711\n",
            "iter_dt 29.13ms; iter 17690: train loss 0.22037\n",
            "iter_dt 27.53ms; iter 17700: train loss 0.23271\n",
            "iter_dt 29.15ms; iter 17710: train loss 0.23997\n",
            "iter_dt 27.12ms; iter 17720: train loss 0.22972\n",
            "iter_dt 29.44ms; iter 17730: train loss 0.22730\n",
            "iter_dt 27.07ms; iter 17740: train loss 0.22715\n",
            "iter_dt 29.10ms; iter 17750: train loss 0.23425\n",
            "iter_dt 27.33ms; iter 17760: train loss 0.23440\n",
            "iter_dt 29.17ms; iter 17770: train loss 0.22129\n",
            "iter_dt 27.10ms; iter 17780: train loss 0.23463\n",
            "iter_dt 29.26ms; iter 17790: train loss 0.22613\n",
            "iter_dt 27.11ms; iter 17800: train loss 0.24486\n",
            "iter_dt 28.99ms; iter 17810: train loss 0.22705\n",
            "iter_dt 27.03ms; iter 17820: train loss 0.22840\n",
            "iter_dt 31.73ms; iter 17830: train loss 0.22516\n",
            "iter_dt 27.48ms; iter 17840: train loss 0.22530\n",
            "iter_dt 27.44ms; iter 17850: train loss 0.22719\n",
            "iter_dt 27.91ms; iter 17860: train loss 0.22649\n",
            "iter_dt 27.25ms; iter 17870: train loss 0.22560\n",
            "iter_dt 28.44ms; iter 17880: train loss 0.21936\n",
            "iter_dt 27.16ms; iter 17890: train loss 0.22579\n",
            "iter_dt 27.25ms; iter 17900: train loss 0.23521\n",
            "iter_dt 27.59ms; iter 17910: train loss 0.22416\n",
            "iter_dt 27.27ms; iter 17920: train loss 0.23217\n",
            "iter_dt 28.11ms; iter 17930: train loss 0.22714\n",
            "iter_dt 27.41ms; iter 17940: train loss 0.24053\n",
            "iter_dt 27.20ms; iter 17950: train loss 0.23254\n",
            "iter_dt 27.44ms; iter 17960: train loss 0.21909\n",
            "iter_dt 27.56ms; iter 17970: train loss 0.23130\n",
            "iter_dt 27.15ms; iter 17980: train loss 0.22382\n",
            "iter_dt 27.10ms; iter 17990: train loss 0.24350\n",
            "iter_dt 27.22ms; iter 18000: train loss 0.22919\n",
            "O God, O God! Neen,\n",
            "van meneer Volmer, hoogleeraar in\n",
            "'t boekhouden en de bedrijfsleer, die vindt, dat je veel te veel\n",
            "naar de lucht kijkt. De God van al die trappen en staan aan den dag van begrep\n",
            "niet gehad en werkte had maar in 't begin van die hooge \"van de kastanjes waren\n",
            "kan af, dat ook zag en die geen vonkje leven in m'n kraan met den sloeiende\n",
            "bovenstal wat rond met verhaal, de knieën van z'n broek uit en keek rond. \"Wat\n",
            "verschaft me het genoegen?\" \"Zeg maar Japi\", zei i, maakte 't\n",
            "pakje los en legde\n",
            "saving model\n",
            "iter_dt 27.17ms; iter 18010: train loss 0.22136\n",
            "iter_dt 27.46ms; iter 18020: train loss 0.22821\n",
            "iter_dt 27.52ms; iter 18030: train loss 0.22885\n",
            "iter_dt 27.24ms; iter 18040: train loss 0.21268\n",
            "iter_dt 27.32ms; iter 18050: train loss 0.22481\n",
            "iter_dt 27.49ms; iter 18060: train loss 0.23799\n",
            "iter_dt 27.19ms; iter 18070: train loss 0.22545\n",
            "iter_dt 27.27ms; iter 18080: train loss 0.21928\n",
            "iter_dt 27.25ms; iter 18090: train loss 0.22759\n",
            "iter_dt 27.41ms; iter 18100: train loss 0.22557\n",
            "iter_dt 27.81ms; iter 18110: train loss 0.22831\n",
            "iter_dt 27.15ms; iter 18120: train loss 0.23163\n",
            "iter_dt 27.71ms; iter 18130: train loss 0.21995\n",
            "iter_dt 27.30ms; iter 18140: train loss 0.24489\n",
            "iter_dt 27.35ms; iter 18150: train loss 0.21147\n",
            "iter_dt 27.80ms; iter 18160: train loss 0.21458\n",
            "iter_dt 27.63ms; iter 18170: train loss 0.23060\n",
            "iter_dt 27.09ms; iter 18180: train loss 0.23417\n",
            "iter_dt 27.38ms; iter 18190: train loss 0.22485\n",
            "iter_dt 27.67ms; iter 18200: train loss 0.22821\n",
            "iter_dt 27.36ms; iter 18210: train loss 0.23718\n",
            "iter_dt 27.22ms; iter 18220: train loss 0.22007\n",
            "iter_dt 27.48ms; iter 18230: train loss 0.23135\n",
            "iter_dt 27.19ms; iter 18240: train loss 0.23360\n",
            "iter_dt 27.16ms; iter 18250: train loss 0.22557\n",
            "iter_dt 27.09ms; iter 18260: train loss 0.22355\n",
            "iter_dt 27.33ms; iter 18270: train loss 0.22631\n",
            "iter_dt 27.14ms; iter 18280: train loss 0.22528\n",
            "iter_dt 27.16ms; iter 18290: train loss 0.21526\n",
            "iter_dt 27.32ms; iter 18300: train loss 0.22463\n",
            "iter_dt 27.39ms; iter 18310: train loss 0.21553\n",
            "iter_dt 27.87ms; iter 18320: train loss 0.22840\n",
            "iter_dt 27.33ms; iter 18330: train loss 0.21440\n",
            "iter_dt 27.23ms; iter 18340: train loss 0.22692\n",
            "iter_dt 27.42ms; iter 18350: train loss 0.23216\n",
            "iter_dt 27.39ms; iter 18360: train loss 0.22975\n",
            "iter_dt 27.92ms; iter 18370: train loss 0.22704\n",
            "iter_dt 29.02ms; iter 18380: train loss 0.22730\n",
            "iter_dt 27.43ms; iter 18390: train loss 0.23036\n",
            "iter_dt 27.16ms; iter 18400: train loss 0.23219\n",
            "iter_dt 27.34ms; iter 18410: train loss 0.22737\n",
            "iter_dt 27.21ms; iter 18420: train loss 0.22772\n",
            "iter_dt 27.02ms; iter 18430: train loss 0.22108\n",
            "iter_dt 27.12ms; iter 18440: train loss 0.21692\n",
            "iter_dt 27.50ms; iter 18450: train loss 0.22293\n",
            "iter_dt 27.21ms; iter 18460: train loss 0.21908\n",
            "iter_dt 27.19ms; iter 18470: train loss 0.21710\n",
            "iter_dt 27.17ms; iter 18480: train loss 0.23813\n",
            "iter_dt 27.24ms; iter 18490: train loss 0.22487\n",
            "iter_dt 27.11ms; iter 18500: train loss 0.23418\n",
            "O God, O God! En maar heb je een snoes dichtertje en heb je jezelf wel zoo wat in de\n",
            "zomernacht en verlangen, dat zij ook 10 minuten te laatste van den stank was 't\n",
            "blootshoofd en steeg op 't bekende.\n",
            "\n",
            "Bavink was een dag uit de stad geweest: \"voor zaken\" zei Japi en\n",
            "toen was hij (Japi) van Houten tegengekomen op weg van kantoor naar\n",
            "huis. Van Houten (een kennis weggelegd. \"Ik ben wereld verversletervend. \"'t Spijt me kerel\",\n",
            "zei ik, \"ik hier niet maffen? Ik ben vannacht niet op mijn bed geweest en\n",
            "vandaag ko\n",
            "saving model\n",
            "iter_dt 27.23ms; iter 18510: train loss 0.24142\n",
            "iter_dt 27.53ms; iter 18520: train loss 0.24141\n",
            "iter_dt 27.32ms; iter 18530: train loss 0.22400\n",
            "iter_dt 27.62ms; iter 18540: train loss 0.22351\n",
            "iter_dt 27.43ms; iter 18550: train loss 0.22899\n",
            "iter_dt 27.26ms; iter 18560: train loss 0.21077\n",
            "iter_dt 27.58ms; iter 18570: train loss 0.22706\n",
            "iter_dt 28.45ms; iter 18580: train loss 0.23134\n",
            "iter_dt 27.42ms; iter 18590: train loss 0.22326\n",
            "iter_dt 27.61ms; iter 18600: train loss 0.23259\n",
            "iter_dt 27.18ms; iter 18610: train loss 0.23460\n",
            "iter_dt 27.26ms; iter 18620: train loss 0.22296\n",
            "iter_dt 27.16ms; iter 18630: train loss 0.23103\n",
            "iter_dt 27.70ms; iter 18640: train loss 0.22878\n",
            "iter_dt 27.50ms; iter 18650: train loss 0.22706\n",
            "iter_dt 27.20ms; iter 18660: train loss 0.22157\n",
            "iter_dt 27.53ms; iter 18670: train loss 0.22424\n",
            "iter_dt 27.71ms; iter 18680: train loss 0.23019\n",
            "iter_dt 29.21ms; iter 18690: train loss 0.22090\n",
            "iter_dt 27.28ms; iter 18700: train loss 0.22612\n",
            "iter_dt 27.31ms; iter 18710: train loss 0.23096\n",
            "iter_dt 27.41ms; iter 18720: train loss 0.22328\n",
            "iter_dt 27.80ms; iter 18730: train loss 0.22746\n",
            "iter_dt 27.52ms; iter 18740: train loss 0.22644\n",
            "iter_dt 27.27ms; iter 18750: train loss 0.21455\n",
            "iter_dt 27.30ms; iter 18760: train loss 0.21163\n",
            "iter_dt 27.24ms; iter 18770: train loss 0.22703\n",
            "iter_dt 27.17ms; iter 18780: train loss 0.22392\n",
            "iter_dt 27.25ms; iter 18790: train loss 0.22950\n",
            "iter_dt 27.34ms; iter 18800: train loss 0.22249\n",
            "iter_dt 27.33ms; iter 18810: train loss 0.21898\n",
            "iter_dt 27.08ms; iter 18820: train loss 0.22373\n",
            "iter_dt 27.18ms; iter 18830: train loss 0.22004\n",
            "iter_dt 27.08ms; iter 18840: train loss 0.22165\n",
            "iter_dt 27.12ms; iter 18850: train loss 0.22698\n",
            "iter_dt 27.16ms; iter 18860: train loss 0.23233\n",
            "iter_dt 27.14ms; iter 18870: train loss 0.22574\n",
            "iter_dt 27.15ms; iter 18880: train loss 0.23133\n",
            "iter_dt 27.28ms; iter 18890: train loss 0.22955\n",
            "iter_dt 27.14ms; iter 18900: train loss 0.21587\n",
            "iter_dt 27.27ms; iter 18910: train loss 0.23590\n",
            "iter_dt 27.24ms; iter 18920: train loss 0.21752\n",
            "iter_dt 27.23ms; iter 18930: train loss 0.22624\n",
            "iter_dt 27.77ms; iter 18940: train loss 0.21907\n",
            "iter_dt 27.06ms; iter 18950: train loss 0.21940\n",
            "iter_dt 27.29ms; iter 18960: train loss 0.23269\n",
            "iter_dt 27.11ms; iter 18970: train loss 0.23614\n",
            "iter_dt 27.21ms; iter 18980: train loss 0.22391\n",
            "iter_dt 27.25ms; iter 18990: train loss 0.23716\n",
            "iter_dt 27.07ms; iter 19000: train loss 0.24097\n",
            "O God, O God! Natuurlijk. Waar hebben\n",
            "we al niet hoe laten door de leven van te drogen\n",
            "en zijn er tusschen zich zoenen. En ik moest mee, 't woel zeggen. Jammer dat i\n",
            "niet brilde. En hij hoorde hem vragen met z'n correcte Museumkwartier\n",
            "geluid: dat vost ik 't wel op dezelfde bank en las er in, schudde weer\n",
            "herhaaldelijk zijn hoofd en kwam toen bij Japi staan, 't copieboek\n",
            "geopend in zijn handen.\n",
            "\n",
            "Japi zat al, wrong niemand die en smakelijk dure jenever wist te drinken als de\n",
            "lui, een leeren en goudgele, leere\n",
            "saving model\n",
            "iter_dt 27.13ms; iter 19010: train loss 0.22231\n",
            "iter_dt 27.38ms; iter 19020: train loss 0.21895\n",
            "iter_dt 27.84ms; iter 19030: train loss 0.23641\n",
            "iter_dt 27.39ms; iter 19040: train loss 0.22786\n",
            "iter_dt 27.29ms; iter 19050: train loss 0.23144\n",
            "iter_dt 27.26ms; iter 19060: train loss 0.22964\n",
            "iter_dt 27.49ms; iter 19070: train loss 0.23442\n",
            "iter_dt 27.88ms; iter 19080: train loss 0.22529\n",
            "iter_dt 27.80ms; iter 19090: train loss 0.22170\n",
            "iter_dt 27.60ms; iter 19100: train loss 0.21925\n",
            "iter_dt 27.37ms; iter 19110: train loss 0.22724\n",
            "iter_dt 27.94ms; iter 19120: train loss 0.22414\n",
            "iter_dt 27.33ms; iter 19130: train loss 0.22237\n",
            "iter_dt 27.95ms; iter 19140: train loss 0.22653\n",
            "iter_dt 27.61ms; iter 19150: train loss 0.22737\n",
            "iter_dt 27.40ms; iter 19160: train loss 0.23643\n",
            "iter_dt 27.37ms; iter 19170: train loss 0.21696\n",
            "iter_dt 27.53ms; iter 19180: train loss 0.22380\n",
            "iter_dt 27.16ms; iter 19190: train loss 0.21775\n",
            "iter_dt 30.51ms; iter 19200: train loss 0.22723\n",
            "iter_dt 27.38ms; iter 19210: train loss 0.22626\n",
            "iter_dt 27.62ms; iter 19220: train loss 0.21195\n",
            "iter_dt 27.75ms; iter 19230: train loss 0.22453\n",
            "iter_dt 27.16ms; iter 19240: train loss 0.24129\n",
            "iter_dt 28.88ms; iter 19250: train loss 0.21625\n",
            "iter_dt 27.36ms; iter 19260: train loss 0.21790\n",
            "iter_dt 28.51ms; iter 19270: train loss 0.22450\n",
            "iter_dt 27.43ms; iter 19280: train loss 0.22987\n",
            "iter_dt 27.22ms; iter 19290: train loss 0.21697\n",
            "iter_dt 27.01ms; iter 19300: train loss 0.22399\n",
            "iter_dt 26.99ms; iter 19310: train loss 0.22048\n",
            "iter_dt 27.73ms; iter 19320: train loss 0.22578\n",
            "iter_dt 27.44ms; iter 19330: train loss 0.22432\n",
            "iter_dt 27.00ms; iter 19340: train loss 0.22528\n",
            "iter_dt 27.07ms; iter 19350: train loss 0.22846\n",
            "iter_dt 27.17ms; iter 19360: train loss 0.21988\n",
            "iter_dt 27.24ms; iter 19370: train loss 0.22566\n",
            "iter_dt 28.41ms; iter 19380: train loss 0.21554\n",
            "iter_dt 27.16ms; iter 19390: train loss 0.21392\n",
            "iter_dt 27.43ms; iter 19400: train loss 0.22735\n",
            "iter_dt 27.27ms; iter 19410: train loss 0.22082\n",
            "iter_dt 27.15ms; iter 19420: train loss 0.22988\n",
            "iter_dt 27.04ms; iter 19430: train loss 0.22168\n",
            "iter_dt 27.12ms; iter 19440: train loss 0.21751\n",
            "iter_dt 27.14ms; iter 19450: train loss 0.22542\n",
            "iter_dt 27.23ms; iter 19460: train loss 0.22632\n",
            "iter_dt 27.17ms; iter 19470: train loss 0.22741\n",
            "iter_dt 27.13ms; iter 19480: train loss 0.21340\n",
            "iter_dt 27.97ms; iter 19490: train loss 0.21456\n",
            "iter_dt 27.36ms; iter 19500: train loss 0.22761\n",
            "O God, O God! Neen, maar de voeten des\n",
            "Vaders, van waar ik ook neerzie op Dora, die is vier uit meer, die Koekebakker,\n",
            "dat ik uit 't schemeren bij de stad geweest: \"voor zaken\" en \"eventueel\"\n",
            "\n",
            "Dat doen zei i, \"die kerels zijn toch nergens anders goed\n",
            "voor dan om ons de doen, als de moest, die zoo raar de deur voor 't open raam. Gek,\n",
            "ze hijgde anders nooit, zijn gedachten tegen naar huis moest en waren dan vallen. Lek mijn\n",
            "lijfje, dat doen ik jou doen moest, die doen groen eind\n",
            "hoog voor onzen boeg in 't wate\n",
            "saving model\n",
            "iter_dt 27.69ms; iter 19510: train loss 0.22754\n",
            "iter_dt 27.90ms; iter 19520: train loss 0.22187\n",
            "iter_dt 27.82ms; iter 19530: train loss 0.23243\n",
            "iter_dt 28.13ms; iter 19540: train loss 0.23119\n",
            "iter_dt 27.32ms; iter 19550: train loss 0.21686\n",
            "iter_dt 27.10ms; iter 19560: train loss 0.22896\n",
            "iter_dt 27.60ms; iter 19570: train loss 0.22256\n",
            "iter_dt 27.63ms; iter 19580: train loss 0.21872\n",
            "iter_dt 27.52ms; iter 19590: train loss 0.23369\n",
            "iter_dt 27.44ms; iter 19600: train loss 0.22262\n",
            "iter_dt 28.67ms; iter 19610: train loss 0.23682\n",
            "iter_dt 27.75ms; iter 19620: train loss 0.23491\n",
            "iter_dt 27.45ms; iter 19630: train loss 0.23197\n",
            "iter_dt 27.29ms; iter 19640: train loss 0.22476\n",
            "iter_dt 29.45ms; iter 19650: train loss 0.22691\n",
            "iter_dt 29.44ms; iter 19660: train loss 0.22755\n",
            "iter_dt 29.29ms; iter 19670: train loss 0.21411\n",
            "iter_dt 29.36ms; iter 19680: train loss 0.22455\n",
            "iter_dt 29.56ms; iter 19690: train loss 0.22173\n",
            "iter_dt 29.29ms; iter 19700: train loss 0.22022\n",
            "iter_dt 29.15ms; iter 19710: train loss 0.23188\n",
            "iter_dt 29.53ms; iter 19720: train loss 0.20497\n",
            "iter_dt 29.56ms; iter 19730: train loss 0.22358\n",
            "iter_dt 29.55ms; iter 19740: train loss 0.22803\n",
            "iter_dt 29.14ms; iter 19750: train loss 0.21722\n",
            "iter_dt 29.00ms; iter 19760: train loss 0.22118\n",
            "iter_dt 29.19ms; iter 19770: train loss 0.22005\n",
            "iter_dt 28.94ms; iter 19780: train loss 0.22050\n",
            "iter_dt 30.00ms; iter 19790: train loss 0.22301\n",
            "iter_dt 29.08ms; iter 19800: train loss 0.22328\n",
            "iter_dt 28.81ms; iter 19810: train loss 0.21867\n",
            "iter_dt 27.76ms; iter 19820: train loss 0.22904\n",
            "iter_dt 27.59ms; iter 19830: train loss 0.21849\n",
            "iter_dt 27.70ms; iter 19840: train loss 0.22255\n",
            "iter_dt 27.20ms; iter 19850: train loss 0.22425\n",
            "iter_dt 27.02ms; iter 19860: train loss 0.22344\n",
            "iter_dt 27.31ms; iter 19870: train loss 0.22673\n",
            "iter_dt 27.27ms; iter 19880: train loss 0.22438\n",
            "iter_dt 27.27ms; iter 19890: train loss 0.22288\n",
            "iter_dt 27.58ms; iter 19900: train loss 0.21763\n",
            "iter_dt 27.13ms; iter 19910: train loss 0.21962\n",
            "iter_dt 27.23ms; iter 19920: train loss 0.22247\n",
            "iter_dt 27.17ms; iter 19930: train loss 0.23433\n",
            "iter_dt 27.45ms; iter 19940: train loss 0.22168\n",
            "iter_dt 27.41ms; iter 19950: train loss 0.21266\n",
            "iter_dt 27.28ms; iter 19960: train loss 0.21687\n",
            "iter_dt 29.30ms; iter 19970: train loss 0.22430\n",
            "iter_dt 27.18ms; iter 19980: train loss 0.21554\n",
            "iter_dt 27.25ms; iter 19990: train loss 0.22486\n",
            "iter_dt 27.47ms; iter 20000: train loss 0.21832\n",
            "O God, O God! Altijd\n",
            "niet verder gekomen zonder wat van die diepende golvendscheid waar iemand schilderde. Hij begreep zelf niet meer. Hij\n",
            "stak z'n arm uit en wees in de ruimte. Dààr waren de dingen. Hij sloeg\n",
            "met z'n vuist tegen z'n voorhoofd. En daar waren ze. Er uit wilden ze,\n",
            "maar ze deden 't niet. Stapelgek werd je ervan. Of niet, of je wat nooit naar de verte getrokken hebben. En wat baat\n",
            "mij de wijsheid, die mij leert dat 't niet anders kan en zoo blijven\n",
            "zal in eeuwigheid?\n",
            "\n",
            "Iederen dag hadden wij ver\n",
            "saving model\n",
            "iter_dt 30.03ms; iter 20010: train loss 0.21126\n",
            "iter_dt 27.32ms; iter 20020: train loss 0.21362\n",
            "iter_dt 27.28ms; iter 20030: train loss 0.21930\n",
            "iter_dt 27.15ms; iter 20040: train loss 0.23586\n",
            "iter_dt 27.15ms; iter 20050: train loss 0.22797\n",
            "iter_dt 27.48ms; iter 20060: train loss 0.22573\n",
            "iter_dt 27.35ms; iter 20070: train loss 0.22116\n",
            "iter_dt 27.17ms; iter 20080: train loss 0.22961\n",
            "iter_dt 27.48ms; iter 20090: train loss 0.22251\n",
            "iter_dt 28.25ms; iter 20100: train loss 0.21666\n",
            "iter_dt 27.40ms; iter 20110: train loss 0.22666\n",
            "iter_dt 27.36ms; iter 20120: train loss 0.21287\n",
            "iter_dt 27.40ms; iter 20130: train loss 0.22252\n",
            "iter_dt 27.28ms; iter 20140: train loss 0.22243\n",
            "iter_dt 27.20ms; iter 20150: train loss 0.22247\n",
            "iter_dt 27.57ms; iter 20160: train loss 0.21161\n",
            "iter_dt 27.43ms; iter 20170: train loss 0.22575\n",
            "iter_dt 27.32ms; iter 20180: train loss 0.22030\n",
            "iter_dt 27.64ms; iter 20190: train loss 0.23130\n",
            "iter_dt 27.86ms; iter 20200: train loss 0.22871\n",
            "iter_dt 27.43ms; iter 20210: train loss 0.21989\n",
            "iter_dt 29.17ms; iter 20220: train loss 0.21240\n",
            "iter_dt 27.42ms; iter 20230: train loss 0.21827\n",
            "iter_dt 27.72ms; iter 20240: train loss 0.21506\n",
            "iter_dt 27.34ms; iter 20250: train loss 0.22501\n",
            "iter_dt 27.23ms; iter 20260: train loss 0.21692\n",
            "iter_dt 27.63ms; iter 20270: train loss 0.22836\n",
            "iter_dt 27.29ms; iter 20280: train loss 0.22076\n",
            "iter_dt 27.39ms; iter 20290: train loss 0.21625\n",
            "iter_dt 28.08ms; iter 20300: train loss 0.22020\n",
            "iter_dt 27.15ms; iter 20310: train loss 0.22764\n",
            "iter_dt 27.98ms; iter 20320: train loss 0.21129\n",
            "iter_dt 27.06ms; iter 20330: train loss 0.22539\n",
            "iter_dt 27.08ms; iter 20340: train loss 0.21653\n",
            "iter_dt 27.19ms; iter 20350: train loss 0.21517\n",
            "iter_dt 27.27ms; iter 20360: train loss 0.22136\n",
            "iter_dt 27.16ms; iter 20370: train loss 0.22459\n",
            "iter_dt 27.28ms; iter 20380: train loss 0.22730\n",
            "iter_dt 27.13ms; iter 20390: train loss 0.22546\n",
            "iter_dt 27.06ms; iter 20400: train loss 0.20877\n",
            "iter_dt 27.14ms; iter 20410: train loss 0.21858\n",
            "iter_dt 27.29ms; iter 20420: train loss 0.21760\n",
            "iter_dt 27.16ms; iter 20430: train loss 0.20488\n",
            "iter_dt 27.16ms; iter 20440: train loss 0.21431\n",
            "iter_dt 27.16ms; iter 20450: train loss 0.22359\n",
            "iter_dt 27.13ms; iter 20460: train loss 0.24126\n",
            "iter_dt 27.43ms; iter 20470: train loss 0.22504\n",
            "iter_dt 27.14ms; iter 20480: train loss 0.22656\n",
            "iter_dt 27.23ms; iter 20490: train loss 0.22120\n",
            "iter_dt 27.29ms; iter 20500: train loss 0.22702\n",
            "O God, O God! Van Nederland, wat is 't stom op een blauwe en\n",
            "gouden hebben keken naar de lucht. Een groote groenachtige ster\n",
            "stond daar te donkeren. \"Je moest zoo maar stilletjes blijven zitten\n",
            "te verlangen zonder te weten waarnaar.\" En hij stopte een versche pijp.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "III.\n",
            "\n",
            "\n",
            "Het was een wonderlijke tijd. Als ik er even over nadenk, dan moet\n",
            "die tijd nog voortduren, die duurt zoolang er jongens van negentien,\n",
            "twintig jaar rondloopen. Maar voor ons is hij lang voorbij.\n",
            "\n",
            "Wij waren boven de wereld en de wereld \n",
            "saving model\n",
            "iter_dt 27.43ms; iter 20510: train loss 0.21952\n",
            "iter_dt 27.47ms; iter 20520: train loss 0.21839\n",
            "iter_dt 27.13ms; iter 20530: train loss 0.21452\n",
            "iter_dt 27.17ms; iter 20540: train loss 0.22136\n",
            "iter_dt 27.20ms; iter 20550: train loss 0.21285\n",
            "iter_dt 27.43ms; iter 20560: train loss 0.22488\n",
            "iter_dt 27.33ms; iter 20570: train loss 0.21350\n",
            "iter_dt 27.15ms; iter 20580: train loss 0.21650\n",
            "iter_dt 27.80ms; iter 20590: train loss 0.22907\n",
            "iter_dt 27.73ms; iter 20600: train loss 0.21501\n",
            "iter_dt 27.66ms; iter 20610: train loss 0.22970\n",
            "iter_dt 27.19ms; iter 20620: train loss 0.22664\n",
            "iter_dt 27.50ms; iter 20630: train loss 0.21230\n",
            "iter_dt 27.39ms; iter 20640: train loss 0.22722\n",
            "iter_dt 27.32ms; iter 20650: train loss 0.22292\n",
            "iter_dt 27.36ms; iter 20660: train loss 0.22403\n",
            "iter_dt 27.50ms; iter 20670: train loss 0.21320\n",
            "iter_dt 27.95ms; iter 20680: train loss 0.21935\n",
            "iter_dt 27.48ms; iter 20690: train loss 0.22105\n",
            "iter_dt 29.22ms; iter 20700: train loss 0.21106\n",
            "iter_dt 27.40ms; iter 20710: train loss 0.21829\n",
            "iter_dt 27.43ms; iter 20720: train loss 0.22716\n",
            "iter_dt 27.29ms; iter 20730: train loss 0.23205\n",
            "iter_dt 27.43ms; iter 20740: train loss 0.21338\n",
            "iter_dt 27.16ms; iter 20750: train loss 0.21548\n",
            "iter_dt 27.21ms; iter 20760: train loss 0.21893\n",
            "iter_dt 27.32ms; iter 20770: train loss 0.23130\n",
            "iter_dt 27.66ms; iter 20780: train loss 0.22533\n",
            "iter_dt 27.09ms; iter 20790: train loss 0.22397\n",
            "iter_dt 27.15ms; iter 20800: train loss 0.21597\n",
            "iter_dt 27.29ms; iter 20810: train loss 0.21173\n",
            "iter_dt 27.42ms; iter 20820: train loss 0.21905\n",
            "iter_dt 27.44ms; iter 20830: train loss 0.22148\n",
            "iter_dt 27.40ms; iter 20840: train loss 0.21575\n",
            "iter_dt 28.00ms; iter 20850: train loss 0.23333\n",
            "iter_dt 27.67ms; iter 20860: train loss 0.22684\n",
            "iter_dt 27.12ms; iter 20870: train loss 0.22887\n",
            "iter_dt 27.09ms; iter 20880: train loss 0.21578\n",
            "iter_dt 27.56ms; iter 20890: train loss 0.21330\n",
            "iter_dt 27.15ms; iter 20900: train loss 0.21097\n",
            "iter_dt 27.37ms; iter 20910: train loss 0.21351\n",
            "iter_dt 27.60ms; iter 20920: train loss 0.22664\n",
            "iter_dt 27.64ms; iter 20930: train loss 0.22860\n",
            "iter_dt 27.55ms; iter 20940: train loss 0.21038\n",
            "iter_dt 27.37ms; iter 20950: train loss 0.20299\n",
            "iter_dt 27.35ms; iter 20960: train loss 0.21827\n",
            "iter_dt 27.51ms; iter 20970: train loss 0.22119\n",
            "iter_dt 27.72ms; iter 20980: train loss 0.21062\n",
            "iter_dt 27.99ms; iter 20990: train loss 0.20991\n",
            "iter_dt 27.30ms; iter 21000: train loss 0.22862\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-987c0c9b526c>\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# run the optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/minGPT/mingpt/trainer.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrigger_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_batch_end'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mtnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/minGPT/mingpt/trainer.py\u001b[0m in \u001b[0;36mtrigger_callbacks\u001b[0;34m(self, onevent)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrigger_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monevent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-987c0c9b526c>\u001b[0m in \u001b[0;36mbatch_end_callback\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"O God, O God!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mcompletion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/minGPT/mingpt/model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, idx, max_new_tokens, temperature, do_sample, top_k)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0midx_cond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# forward the model to get the logits for the index in the sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_cond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0;31m# pluck the logits at the final step and scale by desired temperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/minGPT/mingpt/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok_emb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/minGPT/mingpt/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlpf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/minGPT/mingpt/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# calculate query, key, values for all heads in batch and move head forward to be the batch dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_embd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, nh, T, hs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_head\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, nh, T, hs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}